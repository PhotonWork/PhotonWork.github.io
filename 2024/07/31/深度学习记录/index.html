<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>深度学习记录 | Photon’s Blog</title><meta name="keywords" content="AI"><meta name="author" content="Photon"><meta name="copyright" content="Photon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="record: 8.1-8.7主要把深度学习基础的网课过了一下，大致了解了一遍。西瓜书看了一百多页，大部分推导还是相对易于理解的，打算下一周主要结合pytorch代码实现一下。 基础知识求导: 如果y和x都是标量则显然,如果x为向量则有  \mathbf{X} &#x3D; \left[ \begin{matrix} x_1 \\x_2\\ \vdots \\ x_n\end{matrix}\right]">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习记录">
<meta property="og:url" content="http://phot0n.com/2024/07/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/index.html">
<meta property="og:site_name" content="Photon’s Blog">
<meta property="og:description" content="record: 8.1-8.7主要把深度学习基础的网课过了一下，大致了解了一遍。西瓜书看了一百多页，大部分推导还是相对易于理解的，打算下一周主要结合pytorch代码实现一下。 基础知识求导: 如果y和x都是标量则显然,如果x为向量则有  \mathbf{X} &#x3D; \left[ \begin{matrix} x_1 \\x_2\\ \vdots \\ x_n\end{matrix}\right]">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg">
<meta property="article:published_time" content="2024-07-31T06:57:07.000Z">
<meta property="article:modified_time" content="2024-09-18T10:57:57.336Z">
<meta property="article:author" content="Photon">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg"><link rel="shortcut icon" href="/img/20170202211516_4B3nj.thumb.1000_0.jpeg"><link rel="canonical" href="http://phot0n.com/2024/07/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习记录',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-18 18:57:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css"> <script src="/live2d-widget/autoload.js"></script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Photon’s Blog" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2022/01/19/K4TwFgDxsJ62tEo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">62</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">41</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Photon’s Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习记录</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-07-31T06:57:07.000Z" title="Created 2024-07-31 14:57:07">2024-07-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-09-18T10:57:57.336Z" title="Updated 2024-09-18 18:57:57">2024-09-18</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">19.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>76min</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>record:</p>
<p>8.1-8.7主要把深度学习基础的网课过了一下，大致了解了一遍。西瓜书看了一百多页，大部分推导还是相对易于理解的，打算下一周主要结合pytorch代码实现一下。</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>求导:</p>
<p>如果y和x都是标量则显然,如果x为向量则有</p>
<script type="math/tex; mode=display">
\mathbf{X} = \left[ \begin{matrix} x_1 \\x_2\\ \vdots \\ x_n\end{matrix}\right]
,\frac{\partial y}{\partial \mathbf{X}} = \left[\frac{\partial y}{\partial x_1 } , \frac{\partial y}{\partial x_2 },\dots,\frac{\partial y}{\partial x_n}\right]</script><p>简言之就是对每个分量求偏导</p>
<p>如果y为向量则有</p>
<script type="math/tex; mode=display">
\mathbf{y} = \left[ \begin{matrix} y_1 \\y_2\\ \vdots \\ y_n\end{matrix}\right]
,\frac{\partial \mathbf{y}}{\partial x} =  \left[ \begin{matrix}\frac{\partial y_1}{\partial x } \\ \frac{\partial y_2}{\partial x }\\ \vdots\\\frac{\partial y_n}{\partial x} \end{matrix} \right]</script><p>如果x和y都为向量则可以先将x视为标量应用后者，再对每一行应用$\frac{\partial y_k}{\partial \mathbf{X}}$ 展开即可，会得到一个矩阵。</p>
<h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>我们将分类错误的样本数占样本总数比例称为错误率，即$E = \frac{a}{m}$ ,样本总数为m，a为错误样本数数。则精度为$1-\frac{a}{m}$ .通常，我们将学习器在训练集上的误差称为<code>训练误差</code>，而将学习器对新样本的误差称为<code>泛化误差</code>。</p>
<p>显然我们的目的是泛化误差尽可能小，但是这并不可控，因为我们只有训练集，而对新样本是未知的，所以我们需要努力将训练误差减小，以期待使得泛化误差更小。但是训练误差过小又会导致过拟合的问题。</p>
<h3 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h3><p>对于学习器的泛化性能需要指标进行度量，也就是性能度量，一般常用的是<code>均方误差</code>，即</p>
<script type="math/tex; mode=display">
E(f;D) = \frac{1}{m} \sum_{i=1}^{m}(f(\mathbf{x_i}) -y_i)^2</script><p>其中样例集为$D = \{(\mathbf{x_1},y_1),\dots,(\mathbf{x_m},y_m)\}$ </p>
<p>一般地如果有特定概率分布的均方误差可以写为</p>
<script type="math/tex; mode=display">
E(f;D) = \int_{x\sim D} (f(\mathbf{x} )-y) p(\mathbf{x})d\mathbf{x}</script><p>对于分类问题，可以借助指示函数$\mathbb I(*)$ 进行衡量</p>
<h3 id="查全率与查准率"><a href="#查全率与查准率" class="headerlink" title="查全率与查准率"></a>查全率与查准率</h3><p>简单从字面意思来说，查准率$P$就是你查到的结果中有多少是符合的，查全率$R$就是在所有应该被查到的结果中你查到了多少</p>
<p>显然它们是一对矛盾的度量，如果综合考虑二者则不太好度量。我们通常用二者的调和平均$F_1$</p>
<script type="math/tex; mode=display">
\frac{1}{F_1} = \frac{1}{2}(\frac{1}{P}+\frac{1}{R})</script><p>更一般的，如果我们更侧重某一方(查准率或查全率)，则可以通过加一个参数来平均一下</p>
<script type="math/tex; mode=display">
\frac{1}{F_1} = \frac{1}{1+\beta ^2}(\frac{1}{P}+\frac{\beta ^2}{R})</script><h3 id="ROC和AUC"><a href="#ROC和AUC" class="headerlink" title="ROC和AUC"></a>ROC和AUC</h3><p>对于一个二分类任务（假定为1表示正类， 0表示负类），对于一个样本，分类的结果总共有四种：</p>
<p>类别实际为1，被分为0，FN（False Negative）</p>
<p>类别实际为1，被分为1，TP（True Positive）</p>
<p>类别实际为0，被分为1，FP（False Positive）</p>
<p>类别实际为0，被分为0，TN（True Negative）</p>
<p>而FPR（False Positive Rate）= FP /（FP + TN），即负类数据被分为正类的比例</p>
<p>TPR（True Positive Rate）= TP /（TP + FN），即正类数据被分为正类的比例</p>
<p>ROC曲线实质上是真正率随假阳性上升的一个函数曲线</p>
<p><img src="https://s2.loli.net/2024/08/09/JoO8qtB67WNR51b.png" alt="image-20240809103352096"></p>
<p>显然，对角线的情况是完全随机预测的情况，该曲线的面积AUC，（Area Under Curve）可以一定程度上衡量学习器。对于分类结果我们通常无法绘制出平滑的曲线，只能绘制一条近似的曲线。方法是逐渐调整我们的分类阈值，近似的曲线上每个点坐标实质上是对一个样本的评估。</p>
<h3 id="代价错误敏感率"><a href="#代价错误敏感率" class="headerlink" title="代价错误敏感率"></a>代价错误敏感率</h3><p>有些问题对于假阴性和假阳性的侧重点不一致，通俗点来说就是”宁缺毋滥”和”宁可错杀三千，不可放走一人”的</p>
<p>区别，令$D^{+}$和$D^{-}$分别代表样例集$D$的正例子集和反例子集，则通过指示函数我们可以得到代价敏感的衡量指标</p>
<script type="math/tex; mode=display">
E(f;d;cost) = \frac{1}{m}(\sum_{\mathbf{x}_i \in D^{+}} \mathbb I(f(\mathbf{x_i})\neq y_i)*cost_{01} + \sum_{\mathbf{x}_i \in D^{-}} \mathbb I(f(\mathbf{x_i}) \neq y_i)*cost_{10})</script><p>其中$cost_{01}$和$cost_{10}$代表了假阳性和假阴性的重视程度的参数。</p>
<h3 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h3><p>这个比较重要。对于测试样本$\mathbf{x}$,其在数据集中的标记为$y_D$,真实的标记为$y$。$f(\mathbf{x};D)$为训练集$D$上学得模型$f$在$\mathbf{x}$上的预测输出。以回归任务为例，其预期期望为</p>
<script type="math/tex; mode=display">
\overline{f}(\mathbf{x}) = E_D(f(\mathbf{x};D))</script><p>方差为</p>
<script type="math/tex; mode=display">
var(\mathbf{x}) = E_D[ (f(\mathbf{x};D)-\overline{f}(\mathbf{x}))^2]</script><p>噪声为</p>
<script type="math/tex; mode=display">
\varepsilon ^2=E_D[(y_D-y)^2]</script><p>期望输出与真实标记只检查便称为偏差，即</p>
<script type="math/tex; mode=display">
bias^2(\mathbf{x}) =(\overline{f}(\mathbf{x}) -y)^2</script><p>通过化简可以得到</p>
<script type="math/tex; mode=display">
E(f;D) = bias^2(\mathbf{x})+var(\mathbf{x}) +\varepsilon ^2</script><h2 id="线性模型及其训练"><a href="#线性模型及其训练" class="headerlink" title="线性模型及其训练"></a>线性模型及其训练</h2><p>给定$n$维输入$\mathbf{x} = [x_1,x_2,\dots,x_n]^T$ 线性模型有一个n维权重和一个标量偏差，即</p>
<script type="math/tex; mode=display">
\mathbf{w} =[w_1,w_2,\dots,w_n]^T,b</script><p>线性模型的输出是其输入的加权和</p>
<script type="math/tex; mode=display">
y = <\mathbf{w},\mathbf{x}> +b = w_1x_1+w_2x_2+\dots+w_nx_n+b</script><p>给定数据集$D = \{(\mathbf{x_1},y_1),\dots,(\mathbf{x_m},y_m)\}$ ,其中每个输入$\mathbf{x}$有$d$个属性(即其为d维向量)，则线性模型试图学习一个$f$ ,使得</p>
<script type="math/tex; mode=display">
f(\mathbf{x_i}) =<\mathbf{w},\mathbf{x_i}> +b ,使得f(\mathbf{x_i})\simeq y_i</script><p>其参数通过最小化损失来学习</p>
<script type="math/tex; mode=display">
\ell(\mathbf{X},\mathbf{y},\mathbf{w},b) = \frac{1}{2n}\sum_{i=1}^n (y_i-<\mathbf{w},\mathbf{x_i}> -b)^2 = \frac{1}{2n}||\mathbf{y}-\mathbf{X}\mathbf{w}-b||^2 \\
\mathbf{w}*,\mathbf{b}* =\mathop{argmin} \limits_{\mathbf{w},b}\ell(\mathbf{X},\mathbf{y},\mathbf{w},b)</script><p>可以通过求导得到显式解，将偏差加入，即$\mathbf{X}\leftarrow[\mathbf{X},1],\mathbf{w} \leftarrow \left[ \begin{matrix} \mathbf{w}\\b\end{matrix}\right]$</p>
<p>损失函数维凸函数求导得最优解</p>
<script type="math/tex; mode=display">
\frac{\partial \ell(\mathbf{X},\mathbf{y},\mathbf{w})}{\partial \mathbf{w}} =0 \\ \rightarrow\frac{1}{n} ( \mathbf{y}-\mathbf{X}\mathbf{w})^T\mathbf{X} = 0 \\ \rightarrow
\mathbf{w*} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}\mathbf{y}</script><p>前提是$\mathbf{X}^T\mathbf{X}$是满秩矩阵或者正定矩阵。但是大部分情况下其不一定是满秩矩阵，可以使用<code>梯度下降</code>的方法去学习参数$\mathbf{w}$</p>
<p>其步骤为</p>
<ul>
<li>挑选初始值$\mathbf{w_0}$ </li>
<li>重复迭代参数,过程如下</li>
</ul>
<script type="math/tex; mode=display">
\mathbf{w}_t = \mathbf{w}_{t-1}-\eta \frac{\partial \ell}{\partial \mathbf{w}_{t-1}}</script><p>其中$\eta$为损失率，不能太小也不能太大，太小可能训练速度比较慢，太大可能会导致振荡(还是比较容易理解的，太大有可能就会绕着那个曲面游走)</p>
<p>然后其实线性模型还有很多衍生和变种，在后面也会提到其也是神经网络中的一环。常见的是对数模型</p>
<script type="math/tex; mode=display">
\ln y = <\mathbf{w},\mathbf{x_i}> +b</script><p>更一般的，对于一个单调可微函数$g(*)$，可以得到广义线性模型</p>
<script type="math/tex; mode=display">
y = g^{-1} (<\mathbf{w},\mathbf{x_i}> +b)</script><p>训练代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data</span>(<span class="params">w,b,nums</span>):</span></span><br><span class="line">    X = torch.normal(<span class="number">0</span>,<span class="number">1</span>,(nums ,len(w)))</span><br><span class="line">    Y = torch.matmul(X,w) +b</span><br><span class="line">    Y += torch.normal(<span class="number">0</span>,<span class="number">0.01</span>,Y.shape)</span><br><span class="line">    <span class="keyword">return</span> X ,Y.reshape((<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">real_w = torch.tensor([<span class="number">1.1</span>,<span class="number">-4.5</span>])</span><br><span class="line">real_b = <span class="number">5.4</span></span><br><span class="line">features,labels = generate_data(real_w,real_b,<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机批量roll数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span>(<span class="params">batch_size,features,labels</span>):</span></span><br><span class="line">    nums = len(features)</span><br><span class="line">    indices = list(range(nums))</span><br><span class="line">    random.shuffle(indices)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,nums,batch_size):</span><br><span class="line">        batch_indices = torch.tensor(indices[i:min(i+batch_size,nums)])</span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices],labels[batch_indices]</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先初始化参数</span></span><br><span class="line">w = torch.normal(<span class="number">0</span>,<span class="number">0.01</span>,size=(<span class="number">2</span>,<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>,requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linreg</span>(<span class="params">X,w,b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X,w) + b</span><br><span class="line"><span class="comment"># 均方误差作损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_loss</span>(<span class="params">y_hat,y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat-y.reshape(y_hat.shape))**<span class="number">2</span>/<span class="number">2</span></span><br><span class="line"><span class="comment">#梯度更新参数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">params,lr,batch_size</span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param -= lr*param.grad /batch_size</span><br><span class="line">            param.grad.zero_()</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">lr = <span class="number">0.03</span></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">net = linreg</span><br><span class="line">loss = squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X ,y <span class="keyword">in</span> data_iter(batch_size,features,labels):</span><br><span class="line">        l = loss(net(X,w,b),y)</span><br><span class="line">        <span class="comment">#求和计算梯度</span></span><br><span class="line">        l.sum().backward()</span><br><span class="line">        <span class="comment">#sgd更新</span></span><br><span class="line">        sgd([w,b],lr,batch_size)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        train_l = loss(net(features,w,b),labels)</span><br><span class="line">        print(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> ,loss <span class="subst">&#123;float(train_l.mean())&#125;</span>&#x27;</span>)</span><br><span class="line">print(w,b)</span><br></pre></td></tr></table></figure>
<p>不过这些都有写好的框架方便我们当调包侠，这里为了学习还是了解一下具体怎么写的。</p>
<h2 id="softmax-回归"><a href="#softmax-回归" class="headerlink" title="softmax 回归"></a>softmax 回归</h2><p>softmax回归模型适用于多分类问题，其简单来说就是通过映射将连续值转为概率分布</p>
<script type="math/tex; mode=display">
\hat{\mathbf{y}} = softmax(\mathbf{o}) \\
\hat{y_i} = \frac{exp({o_i})}{\sum_k exp({o_k})}</script><p>交叉熵用来衡量两个概率之间的差别,即</p>
<script type="math/tex; mode=display">
H(\mathbf{p},\mathbf{q}) = \sum_i -p_ilog(q_i)</script><p>其作为损失则有</p>
<script type="math/tex; mode=display">
l(\mathbf{y},\hat{\mathbf{y}}) =\sum_i -y_ilog(\hat{y_i})\\=-\sum_iy_i\log\frac{exp(o_i)}{\sum_jexp(o_j)} \\=-\sum_iy_io_i+\sum_iy_ilog(\sum_jexp(o_j))\\=-\sum_iy_io_i+log(\sum_jexp(o_j))</script><p>对其求梯度</p>
<script type="math/tex; mode=display">
\frac{\partial{l(\mathbf{y},\hat{\mathbf{y}}) }}{\partial o_i} = -y_i+\frac{exp(o_i)}{\sum_jexp(o_j)}\\=softmax(o_i)-y_i</script><p>对其训练代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display </span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter ,test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line">num_input = <span class="number">784</span></span><br><span class="line">num_output = <span class="number">10</span></span><br><span class="line">w = torch.normal(<span class="number">0</span>,<span class="number">0.01</span>,size = (num_input,num_output),requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(num_output,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Accumnlator</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span> (<span class="params">self,n</span>):</span></span><br><span class="line">        self.data = [<span class="number">0.0</span>] *n </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">self,*args</span>):</span></span><br><span class="line">        self.data = [a+float(b) <span class="keyword">for</span> a,b <span class="keyword">in</span> zip(self.data,args)]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data = [<span class="number">0.0</span>]*len(self.data)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self,idx</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(w.shape)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">X</span>):</span></span><br><span class="line">    X_exp = torch.exp(X)</span><br><span class="line">    partition = X_exp.sum(<span class="number">1</span>,keepdim=<span class="literal">True</span>) <span class="comment">#对行求和</span></span><br><span class="line">    <span class="keyword">return</span> X_exp/partition</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="keyword">return</span> softmax(torch.matmul(X.reshape((<span class="number">-1</span>,w.shape[<span class="number">0</span>])) ,w) +b)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span>(<span class="params">y_hat,y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> -torch.log(y_hat[range(len(y_hat)),y]) <span class="comment">#在相应标号拿到相应的值，取log</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">y_hat,y</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(len(y_hat.shape) &gt;<span class="number">1</span> <span class="keyword">and</span> y_hat.shape[<span class="number">1</span>] &gt;<span class="number">1</span>):</span><br><span class="line">        y_hat = y_hat.argmax(axis = <span class="number">1</span>)</span><br><span class="line">    com = y_hat.type(y.dtype) ==y </span><br><span class="line">    <span class="keyword">return</span> float(com.type(y.dtype).sum())</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accurate</span>(<span class="params">net,data_iter</span>):</span></span><br><span class="line">    <span class="keyword">if</span>( isinstance(net,torch.nn.Module)):</span><br><span class="line">        net.eval()</span><br><span class="line">    metric =Accumnlator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        metric.add(accuracy(net(X) ,y) ,y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] /metric[<span class="number">1</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch_ch3</span>(<span class="params">net,train_iter,loss,updater</span>):</span></span><br><span class="line">    <span class="keyword">if</span>(isinstance(net,torch.nn.Module)):</span><br><span class="line">        net.train()</span><br><span class="line">    metric = Accumnlator(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        l = loss(y_hat,y) <span class="comment">##计算损失函数</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(updater,torch.optim.Optimizer):</span><br><span class="line">            updater.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            updater.step()</span><br><span class="line">            metric.add(float(l)*len(y),accuracy(y_hat,y),y.size.numel())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l.sum().backward()</span><br><span class="line">            updater(X.shape[<span class="number">0</span>]) <span class="comment">##更新参数</span></span><br><span class="line">            metric.add(float(l.sum()) ,accuracy(y_hat,y),y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] /metric[<span class="number">2</span>] ,metric[<span class="number">1</span>] /metric[<span class="number">2</span>] <span class="comment">#前者为loss，后者为准确率</span></span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updater</span>(<span class="params">batch_size</span>):</span></span><br><span class="line">    <span class="keyword">return</span> d2l.sgd([w, b], lr, batch_size)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">net,train_iter,loss,num_epochs,updater</span>):</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_metric = train_epoch_ch3(net,train_iter,loss,updater)</span><br><span class="line">        <span class="comment"># test_acc = evaluate_accurate(net,test_iter)</span></span><br><span class="line">        print(<span class="string">f&quot;loss = <span class="subst">&#123;train_metric[<span class="number">0</span>]&#125;</span> , train_acc = <span class="subst">&#123;train_metric[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># print(evaluate_accurate(net,test_iter))</span></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">train(net,train_iter,cross_entropy,num_epochs,updater)</span><br></pre></td></tr></table></figure>
<h2 id="神经网络与感知机"><a href="#神经网络与感知机" class="headerlink" title="神经网络与感知机"></a>神经网络与感知机</h2><p>简单来说，神经网络模型模拟了生物系统中神经元的传递(回忆一下高中生物知识，虽然已经忘差不多了)</p>
<p>神经网络中最基本的成分是神经元模型，在神经网络当中，每个神经元与其他神经元相连。当其兴奋的时候会向其他神经元发送电信号。而每个神经元有一个阈值，如果接收到的电信号超过了当前阈值就会被激活，也就是兴奋。再向其他神经元传递。</p>
<p><img src="https://s2.loli.net/2024/08/10/whmg2a5VnDETWor.png" alt="image-20240810144253560"></p>
<p>将其用数学公式表达则有</p>
<script type="math/tex; mode=display">
y = f(\sum_{i=1} ^n w_ix_i-\theta)\\=f(<\mathbf{w},\mathbf{x>-\theta})</script><p>其中$w_i$代表了第$i$个神经元的权重，$x_i$代表了第$i$个神经元的输入，$\theta$代表阈值，$f$为激活函数，常见的是sgn函数以及$sigmod$函数</p>
<p>神经网络就是将许许多多这样的神经元模型组合在一起 ，常见模型如下(神经元之间不存在同层连接与跨层连接,称为”多层前馈神经网络”)，输入层与输出层之间的称为隐含层</p>
<p><img src="https://s2.loli.net/2024/08/10/MXuhv3D9md7Kfjb.png" alt="image-20240810150059221"></p>
<p>训练多层网络使用的是误差逆传播算法(BP算法)，其还是基于梯度下降策略，对任意参数$v$更新为</p>
<script type="math/tex; mode=display">
v \leftarrow v+\Delta v</script><p>使用该方法列式子对每个参数求梯度即可，主要在计算仔细一点，理解难度不大</p>
<p>其数学推导如下</p>
<p>对于之前softmax回归模型使用的Fashion-MNIST数据集 (每个图像由28*28=784个灰度像素值组成)，改为用多层感知机模型，其训练代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入的大小，即784个灰度像素值代表的向量</span></span><br><span class="line"><span class="comment">#输出大小，10个分类</span></span><br><span class="line"><span class="comment">#单个隐藏层中隐藏单元个数 256个</span></span><br><span class="line">num_inputs, num_outputs, num_hiddens = <span class="number">784</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#隐藏层参数</span></span><br><span class="line">W1 = nn.Parameter(torch.randn(</span><br><span class="line">    num_inputs, num_hiddens, requires_grad=<span class="literal">True</span>) * <span class="number">0.01</span>)</span><br><span class="line">b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出层参数</span></span><br><span class="line">W2 = nn.Parameter(torch.randn(</span><br><span class="line">    num_hiddens, num_outputs, requires_grad=<span class="literal">True</span>) * <span class="number">0.01</span>)</span><br><span class="line">b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">params = [W1, b1, W2, b2]</span><br><span class="line"></span><br><span class="line"><span class="comment">#relu函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span>(<span class="params">X</span>):</span></span><br><span class="line">    a = torch.zeros_like(X)</span><br><span class="line">    <span class="keyword">return</span> torch.max(X, a)</span><br><span class="line"></span><br><span class="line"><span class="comment">#多层感知机</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span>(<span class="params">X</span>):</span></span><br><span class="line">    X = X.reshape((<span class="number">-1</span>, num_inputs))</span><br><span class="line">    H = relu(X@W1 + b1)  </span><br><span class="line">    <span class="keyword">return</span> (H@W2 + b2)</span><br><span class="line"><span class="comment"># 交叉熵作损失函数</span></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">num_epochs, lr = <span class="number">10</span>, <span class="number">0.1</span></span><br><span class="line"><span class="comment">#梯度下降</span></span><br><span class="line">updater = torch.optim.SGD(params, lr=lr)</span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)</span><br><span class="line"></span><br><span class="line">d2l.predict_ch3(net, test_iter)</span><br></pre></td></tr></table></figure>
<h2 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h2><h3 id="权重衰退"><a href="#权重衰退" class="headerlink" title="权重衰退"></a>权重衰退</h3><p>主要为了在一定程度上解决过拟合问题，调整模型的复杂度。一种简单的方法是在损失函数中添加参数的L2范数,即</p>
<script type="math/tex; mode=display">
L(\mathbf{w},b) +\frac{\lambda}{2} ||\mathbf{w}||^2</script><p>其中L2的范数即向量每个分量的平方和。计算梯度进行参数更新如下</p>
<script type="math/tex; mode=display">
\frac{\partial{}}{\partial{\mathbf{w}}} (L(\mathbf{w},b) +\frac{\lambda}{2} ||\mathbf{w}||^2) = \frac{\partial{L(\mathbf{w},b)}}{\partial{\mathbf{w}}} +\lambda \mathbf{w}</script><p>更新参数</p>
<script type="math/tex; mode=display">
w \leftarrow w-\eta \frac{\partial{}}{\partial{\mathbf{w}}} (L(\mathbf{w},b) +\frac{\lambda}{2} ||\mathbf{w}||^2) =(1-\eta\lambda) w- \eta \frac{\partial{L(\mathbf{w},b)}}{\partial{\mathbf{w}}}</script><p>使用torch的实现方式如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment">#这里问题的维数为200维，但是训练集只包含20个样本</span></span><br><span class="line">n_train, n_test, num_inputs, batch_size = <span class="number">20</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">5</span></span><br><span class="line">true_w, true_b = torch.ones((num_inputs, <span class="number">1</span>)) * <span class="number">0.01</span>, <span class="number">0.05</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成y=Xw+b+noise的训练数据</span></span><br><span class="line">train_data = d2l.synthetic_data(true_w, true_b, n_train)</span><br><span class="line">train_iter = d2l.load_array(train_data, batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成测试数据</span></span><br><span class="line">test_data = d2l.synthetic_data(true_w, true_b, n_test)</span><br><span class="line">test_iter = d2l.load_array(test_data, batch_size, is_train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化模型参数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_params</span>():</span></span><br><span class="line">    w = torch.normal(<span class="number">0</span>, <span class="number">1</span>, size=(num_inputs, <span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">    b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> [w, b]</span><br><span class="line"></span><br><span class="line"><span class="comment">#L2范数惩罚</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l2_penalty</span>(<span class="params">w</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.sum(w.pow(<span class="number">2</span>)) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">lambd</span>):</span></span><br><span class="line">    w, b = init_params()</span><br><span class="line">    <span class="comment">#线性模型</span></span><br><span class="line">    net, loss = <span class="keyword">lambda</span> X: d2l.linreg(X, w, b), d2l.squared_loss</span><br><span class="line">    num_epochs, lr = <span class="number">100</span>, <span class="number">0.003</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            <span class="comment"># 增加了L2范数惩罚项，</span></span><br><span class="line">            <span class="comment"># 广播机制使l2_penalty(w)成为一个长度为batch_size的向量</span></span><br><span class="line">            l = loss(net(X), y) + lambd * l2_penalty(w)</span><br><span class="line">            l.sum().backward()</span><br><span class="line">            <span class="comment">#梯度更新参数</span></span><br><span class="line">            d2l.sgd([w, b], lr, batch_size)</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">&#x27;w的L2范数是：&#x27;</span>, torch.norm(w).item())</span><br></pre></td></tr></table></figure>
<h3 id="暂退法"><a href="#暂退法" class="headerlink" title="暂退法"></a>暂退法</h3><p>其主要思想是:</p>
<ul>
<li><p>1.在每次迭代中,随机选择一部分神经元,暂时不让其激活,即dropout。</p>
</li>
<li><ol>
<li>剩下的神经元则需要完成原任务,避免过拟合。</li>
</ol>
</li>
<li><ol>
<li>每次迭代dropout的节点不同,强迫整个网络协作,避免对特定节点的依赖。</li>
</ol>
</li>
<li><ol>
<li>在预测时则不使用dropout。</li>
</ol>
</li>
</ul>
<p><img src="https://s2.loli.net/2024/08/11/tLQyTo7FHO2E4hf.png" alt="image-20240811154915491"></p>
<p>其简洁实现如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mport torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line">net = nn.Sequential(nn.Flatten(),</span><br><span class="line">        nn.Linear(<span class="number">784</span>, <span class="number">256</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        <span class="comment"># 在第一个全连接层之后添加一个dropout层</span></span><br><span class="line">        nn.Dropout(dropout1),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        <span class="comment"># 在第二个全连接层之后添加一个dropout层</span></span><br><span class="line">        nn.Dropout(dropout2),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">m</span>):</span></span><br><span class="line">    <span class="keyword">if</span> type(m) == nn.Linear:</span><br><span class="line">        nn.init.normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">net.apply(init_weights);</span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>
<h2 id="一些常用的深度学习API组件使用"><a href="#一些常用的深度学习API组件使用" class="headerlink" title="一些常用的深度学习API组件使用"></a>一些常用的深度学习API组件使用</h2><h3 id="自定义层和块"><a href="#自定义层和块" class="headerlink" title="自定义层和块"></a>自定义层和块</h3><p>层类似多层感知机的层一样，而块可以描述单个层、由多个层组成的组件或整个模型本身。一个块甚至可能由多个块组成(套娃)</p>
<p>每个块的子类必须定义一个<code>前向传播函数</code>,描述一个将输入转换为输出的过程。我们自定义一个块的时候，必须提供一些基本功能</p>
<ul>
<li>将输入数据作为其前向传播函数的参数</li>
<li>通过前向传播函数来生成输出</li>
<li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。</li>
<li>存储和访问前向传播计算所需的参数。</li>
<li>根据需要初始化模型参数。</li>
</ul>
<p>例如如下编码实现的一个块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 用模型参数声明层。这里，我们声明两个全连接的层</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 调用MLP的父类Module的构造函数来执行必要的初始化。</span></span><br><span class="line">        <span class="comment"># 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)  <span class="comment"># 隐藏层</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)  <span class="comment"># 输出层</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="comment"># 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。</span></span><br><span class="line">        <span class="keyword">return</span> self.out(F.relu(self.hidden(X)))</span><br></pre></td></tr></table></figure>
<p>为了将多个块组合在一起，我们使用了Sequential类</p>
<p>其实现类似这样(这个是自定义的简化Sequential类)，在init函数中将参数中每个模块添加到列表_modules中，而在前向传播函数forward中，依次调用添加的块，然后进行计算，传递给下一个块计算，以此类推</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySequential</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *args</span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="keyword">for</span> idx, module <span class="keyword">in</span> enumerate(args):</span><br><span class="line">            <span class="comment"># 这里，module是Module子类的一个实例。我们把它保存在&#x27;Module&#x27;类的成员</span></span><br><span class="line">            <span class="comment"># 变量_modules中。_module的类型是OrderedDict</span></span><br><span class="line">            self._modules[str(idx)] = module</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="comment"># OrderedDict保证了按照成员添加的顺序遍历它们</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self._modules.values():</span><br><span class="line">            X = block(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">net = MySequential(nn.Linear(<span class="number">20</span>, <span class="number">256</span>), nn.ReLU(), nn.Linear(<span class="number">256</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>而自定义层的方法如下，主要是自己实现一个类，实现前向传播函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment">#不带参数的层</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CenteredLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> X - X.mean()</span><br><span class="line"><span class="comment"># 带参数的层</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLinear</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_units, units</span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.randn(in_units, units))</span><br><span class="line">        self.bias = nn.Parameter(torch.randn(units,))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        linear = torch.matmul(X, self.weight.data) + self.bias.data</span><br><span class="line">        <span class="keyword">return</span> F.relu(linear)</span><br></pre></td></tr></table></figure>
<h3 id="读写与存储"><a href="#读写与存储" class="headerlink" title="读写与存储"></a>读写与存储</h3><p>主要是保存模型参数。保存张量的参数方法类似</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.hidden = nn.Linear(<span class="number">20</span>, <span class="number">256</span>)</span><br><span class="line">        self.output = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.output(F.relu(self.hidden(x)))</span><br><span class="line"></span><br><span class="line">net = MLP()</span><br><span class="line">X = torch.randn(size=(<span class="number">2</span>, <span class="number">20</span>))</span><br><span class="line">Y = net(X)</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存参数到mlp.params中</span></span><br><span class="line">torch.save(net.state_dict(), <span class="string">&#x27;mlp.params&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从mlp.params中load参数</span></span><br><span class="line">clone = MLP()</span><br><span class="line">clone.load_state_dict(torch.load(<span class="string">&#x27;mlp.params&#x27;</span>))</span><br><span class="line">clone.eval()</span><br><span class="line"></span><br><span class="line"><span class="comment">#保存张量</span></span><br><span class="line">x = torch.arange(<span class="number">4</span>)</span><br><span class="line">torch.save(x, <span class="string">&#x27;x-file&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load张量</span></span><br><span class="line">x2 = torch.load(<span class="string">&#x27;x-file&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="使用GPU"><a href="#使用GPU" class="headerlink" title="使用GPU"></a>使用GPU</h3><p>在pytorch中，使用<code>torch.device</code>函数来指定使用cpu或者gpu，后者采用<code>touch.device(f&#39;cuda:&#123;id&#125;&#39;)</code>的方式，<code>id</code>取决于你有几个GPU，使用哪块gpu。需要注意的是，我们需要保证存储在GPU上进行运算的两个参数位于同一个GPU上面，否则需要进行复制传递过去</p>
<p>例如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span>(<span class="params">i=<span class="number">0</span></span>):</span>  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;如果存在，则返回gpu(i)，否则返回cpu()&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.device_count() &gt;= i + <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.device(<span class="string">f&#x27;cuda:<span class="subst">&#123;i&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">X = torch.ones(<span class="number">2</span>, <span class="number">3</span>, device=try_gpu()) <span class="comment">#张量X存在第0块GPU中</span></span><br><span class="line">Y = torch.rand(<span class="number">2</span>, <span class="number">3</span>, device=try_gpu(<span class="number">1</span>))<span class="comment">#张量Y存在第1块GPU中</span></span><br><span class="line"></span><br><span class="line">Z = X.cuda(<span class="number">1</span>) <span class="comment">#复制到GPU1中，才能进行计算</span></span><br><span class="line">Y + Z</span><br></pre></td></tr></table></figure>
<p>类似的，可以将神经网络模型指定GPU,下列代码将模型参数放在GPU上面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(nn.Linear(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">net = net.to(device=try_gpu())</span><br></pre></td></tr></table></figure>
<p>这里顺便介绍一下GPU的工作原理</p>
<p>笔者曾经大二的时候打过ASC世界超算竞赛，当时学了一点GPU和并行计算的知识(不过现在已经基本上忘完了)</p>
<p>对比一下CPU和GPU的架构如下图所示(网图，侵删)</p>
<p><img src="https://s2.loli.net/2024/08/13/3GiCXvjgHh2aIW8.png" alt="image-20240813111428744"></p>
<p>可以看出来，GPU相较于CPU减少了cache，控制单元的部分，并且转向了使用大量的ALU还提高其计算能力和吞吐量。但是学过系统结构的我们知道，cache的存在解决了读写速度不匹配的问题。而GPU削减cache会在一定程度上导致高延迟(一部分时间耗在了IO读取上面)。那么GPU怎么解决这个问题并提供高性能的呢。其解决方法是使用大量线程和强大的计算能力，在延迟期间有效调度线程执行，从而提高性能。</p>
<p>GPU 由一系列   流式多处理器 (streaming multiprocessors (SM) ) 组成。每个 SM 又由多个流处理器或内核或线程组成。</p>
<p>每个SM有共享存储器，在所有内核当中共享，还有功能单元或其他计算单元。(感觉可以理解成一个丐版的CPU核心？)</p>
<p>SM的内存层次结构如下图所示(网图侵删)</p>
<p><img src="https://s2.loli.net/2024/08/13/QhUD9tvGfClipES.png" alt="image-20240813112639657"></p>
<p>其中</p>
<ul>
<li><code>register</code>就是寄存器，在内核当中共享，并根据线程要求动态分配。分配后是线程私有的。</li>
<li><code>Shared Memory</code> 共享内存，为运行在SM上的线程块共享。</li>
<li><code>Global Memory</code> 全局内存，所有SM共享，可以通过L2 cache进行缓存。</li>
<li><code>Constant caches</code>常量缓存，必须在代码中显示声明对象为常量才会缓存在其上面</li>
</ul>
<p>剩下得L1 cache和L2 cache和CPU的cache类似。</p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>卷积神经网络的一个切入点是<code>空间不变性</code>。举一个例子，如果我们想要训练一个模型来识别图片上的某些模式(比如识别一个人脸)，显然我们想要的结果是无论这张人脸在照片的左上角还是右下角,我们都应该正确识别。还有一个特点是<code>局部性</code>，解释为神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系。我个人的理解是它主要应用于类似局部模式匹配，从某个平移窗口中search东西，而不是以整个照片为目标进行一个找的查。</p>
<p>如果将其用数学语言描述，输入是一个二维图像$\mathbf{X}$,隐藏表示为$\mathbf{H}$ ,他俩都是二位张量，具有相同的形状，而我们的权重$W$是一个<code>四阶张量</code>(很好理解,因为固定两维之后还剩两维去和输入进行假)，再加上我们的偏置矩阵$U$,则有对某个位置$(i,j)$的像素，有</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i,j} = [\mathbf{U}]_{i,j} + \sum_k\sum_l [\mathbf{W}]_{i,j,k,l}[\mathbf{X}]_{k,l} \\=[\mathbf{U}]_{i,j} + \sum_a\sum_b [\mathbf{V}]_{i,j,a,b}[\mathbf{X}]_{i+a,j+b}</script><p>等式也很好理解（《具体数学》的和式那节有提到处理和式的方法)，就是下表重新索引。对于平移不变性，意味着我们有$\mathbf{U},\mathbf{V}$ 不依赖于$(i,j)$的选择，则其可以定义为</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i,j} = u+\sum_a\sum_b[\mathbf{V}]_{a,b} [\mathbf{X}]_{i+a,j+b}</script><p>对局部性可以这样描述，在$|a| &gt;\Delta \or |b| &gt;\Delta \rightarrow [\mathbf{V}]_{a,b} = 0$ 。因此则有</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i,j} = u+\sum_{a=-\Delta}^{\Delta}\sum_{b=-\Delta} ^{\Delta}[\mathbf{V}]_{a,b} [\mathbf{X}]_{i+a,j+b}</script><p>$\mathbf{V}$被称为卷积核或者滤波器，或者是卷积层参数，是一个可学习的参数。这样卷积神经网络相较于多层感知机，其需要学习的参数大幅减少，得益于我们的平移不变性以及局部性。但是坏处是如果图像不满足平移不变的时候，模型可能难以拟合训练数据</p>
<h3 id="互相关运算"><a href="#互相关运算" class="headerlink" title="互相关运算"></a>互相关运算</h3><p>就是核函数在输入矩阵上面不断地平移窗口，作互相关运算，到输出矩阵。比如说蓝色区域有 19 = 0x0+1x1+3x2+4x3。以此类推</p>
<p><img src="https://s2.loli.net/2024/08/12/rdeQTjOvRaE2FnV.png" alt="image-20240812102906231"></p>
<p>其代码实现如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span>(<span class="params">X, K</span>):</span>  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot;</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>
<p>所以我们可以构造卷积层的前向传播函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size</span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.weight = nn.Parameter(torch.rand(kernel_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure>
<p>对于卷积层还有填充以及步幅等优化手段。</p>
<p>填充主要针对的是在应用多层卷积的时候，会丢失边缘像素。为了不丢失这些边缘像素，保持输入输出具有相同规模，我们对输入矩阵的四周进行填充(常常补0)，如下图所示</p>
<p><img src="https://s2.loli.net/2024/08/12/yIGuxpF3gq9oLaC.png" alt="image-20240812104637620"></p>
<p>回忆我们刚刚应用互相关时的过程，就是类似核函数在输入矩阵中一步一步的平移窗口，而此时步幅就是1.我们可以对步幅进行更改(分为水平步幅$s_w$和垂直步幅$s_h$)。这样得到的输出矩阵形状为($p_h$为垂直填充，$p_w$为水平填充)</p>
<script type="math/tex; mode=display">
\lfloor (n_h-k_h+p_h+s_h)/s_h\rfloor *\lfloor (n_w-k_w+p_w+s_w)/s_w\rfloor</script><h3 id="汇聚层"><a href="#汇聚层" class="headerlink" title="汇聚层"></a>汇聚层</h3><p>汇聚层有两个目的</p>
<ul>
<li>降低卷积层对位置的敏感性</li>
<li>降低对空间降采样表示的敏感性</li>
</ul>
<p>和卷积层类似，汇聚层也是像滑动窗口一样，在输入的矩阵上面滑动进行运算。汇聚层不包含参数(区别于卷积层的核函数)。常见的汇聚层操作有<code>最大汇聚层</code>以及<code>平均汇聚层</code>。代表了在相应窗口取最大值或者平均值</p>
<p><img src="https://s2.loli.net/2024/08/12/dxvZzQoWFpUDO2j.png" alt="image-20240812163656153"></p>
<p>其代码实现如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].max()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>
<p>类似的，汇聚层也有类似卷积层那样填充或者改变步幅等操作。也能作用于多个通道</p>
<h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><p>LeNet构成示意图如下,其主要由两部分组成</p>
<ul>
<li>卷积编码器</li>
<li>全连接层密集块</li>
</ul>
<p><img src="https://s2.loli.net/2024/08/12/CJuTvtKUOwzEWD3.png" alt="image-20240812202154844"></p>
<p>一个卷积块(回忆我们之前学的块和层)基本单元是一个卷积层，一个sigmoid激活函数和一个平均汇聚层。</p>
<p>每个卷积核使用5*5的卷积核和一个sigmoid激活函数。第一卷积层有6个输出通道，第二个卷积层有16个输出通道。每个池操作是2*2的，步幅是2。用代码实现如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(), <span class="comment">#输入1 ，6通道，核函数5*5，填充2 ，得到的还是28*28</span></span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), <span class="comment">#平均池化，2*2 步幅是2，得到的是 14*14</span></span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(), <span class="comment">#输入6 ，16通道，核函数5*5，得到10*10</span></span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), <span class="comment">#平均池化，2*2 步幅是2得到5*5</span></span><br><span class="line">    nn.Flatten(), <span class="comment">#展开，得到的是16个通道*5*5矩阵=16*5*5个元素</span></span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(), <span class="comment">#全连接层，16*5*5个元素输入</span></span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(), <span class="comment">#全连接层</span></span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)) <span class="comment">#全连接层</span></span><br></pre></td></tr></table></figure>
<p>其训练代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy_gpu</span>(<span class="params">net, data_iter, device=None</span>):</span> <span class="comment">#@save</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(net, nn.Module):</span><br><span class="line">        net.eval()  <span class="comment"># 设置为评估模式</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> device:</span><br><span class="line">            device = next(iter(net.parameters())).device</span><br><span class="line">    <span class="comment"># 正确预测的数量，总预测的数量</span></span><br><span class="line">    metric = d2l.Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> isinstance(X, list):</span><br><span class="line">                X = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            metric.add(d2l.accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch6</span>(<span class="params">net, train_iter, test_iter, num_epochs, lr, device</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;用GPU训练模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">m</span>):</span></span><br><span class="line">        <span class="keyword">if</span> type(m) == nn.Linear <span class="keyword">or</span> type(m) == nn.Conv2d:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">    net.apply(init_weights) <span class="comment">#初始化参数</span></span><br><span class="line">    print(<span class="string">&#x27;training on&#x27;</span>, device)</span><br><span class="line">    net.to(device) <span class="comment">#绑定GPU</span></span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                            legend=[<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>, <span class="string">&#x27;test acc&#x27;</span>])</span><br><span class="line">    timer, num_batches = d2l.Timer(), len(train_iter)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        <span class="comment"># 训练损失之和，训练准确率之和，样本数</span></span><br><span class="line">        metric = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> i, (X, y) <span class="keyword">in</span> enumerate(train_iter):</span><br><span class="line">            timer.start()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y) <span class="comment">#计算损失</span></span><br><span class="line">            l.backward() <span class="comment">#传播</span></span><br><span class="line">            optimizer.step() <span class="comment">#更新参数</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                metric.add(l * X.shape[<span class="number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="number">0</span>])</span><br><span class="line">            timer.stop()</span><br><span class="line">            train_l = metric[<span class="number">0</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            train_acc = metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % (num_batches // <span class="number">5</span>) == <span class="number">0</span> <span class="keyword">or</span> i == num_batches - <span class="number">1</span>:</span><br><span class="line">                animator.add(epoch + (i + <span class="number">1</span>) / num_batches,</span><br><span class="line">                             (train_l, train_acc, <span class="literal">None</span>))</span><br><span class="line">        test_acc = evaluate_accuracy_gpu(net, test_iter)</span><br><span class="line">        animator.add(epoch + <span class="number">1</span>, (<span class="literal">None</span>, <span class="literal">None</span>, test_acc))</span><br><span class="line">    print(<span class="string">f&#x27;loss <span class="subst">&#123;train_l:<span class="number">.3</span>f&#125;</span>, train acc <span class="subst">&#123;train_acc:<span class="number">.3</span>f&#125;</span>, &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;test acc <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    print(<span class="string">f&#x27;<span class="subst">&#123;metric[<span class="number">2</span>] * num_epochs / timer.sum():<span class="number">.1</span>f&#125;</span> examples/sec &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;on <span class="subst">&#123;str(device)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Modern-CNN"><a href="#Modern-CNN" class="headerlink" title="Modern CNN"></a>Modern CNN</h2><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><img src="https://s2.loli.net/2024/08/13/JuCOwar8iDV7ZgU.png" alt="image-20240813155854708"></p>
<p>网络的整体结构如上图所示。从左到右依次是输入层，五个卷积层(C1-C5),两个全连接层和一个输出层。</p>
<p>论文中提到由于AlexNet比较复杂，参数量很大，而加上当时硬件资源限制，所以不太好在一块GPU上进行训练，而是采用两路GPU进行并行训练。</p>
<p>输入层的大小是 224*224*3(实际的图像尺寸似乎是227*227*3?)。</p>
<p>从左到右依次介绍各个卷积层的构成。</p>
<p>最左边那个卷积层C1处理流程是 <code>卷积 -&gt;ReLu -&gt;局部相应归一化(LRN) -&gt;池化</code></p>
<p>卷积核是11*11*3,有96个，padding=0，stride=4，得到输出的窗口大小是 (227+2<em>0-11)/4+1 = 55,所以输出是55\</em>55*96（在图中其实是分成了两半，原因前文说过，采用了两路GPU并行训练)</p>
<p>ReLu就是将输出的FeatureMap输入到ReLu函数中</p>
<p>局部相应归一化的公式如下</p>
<script type="math/tex; mode=display">
b_{x,y} ^i = a_{x,y} ^i /(k+\alpha \sum_{j = max(0,i-\frac{n}{2})}^{min(N-1,i+\frac{n}{2})} (a_{x,y})^2)^\beta</script><p>局部响应归一化层简称LRN，是在深度学习中提高准确度的技术方法。一般是在激活、池化后进行。LRN对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元(其实式子分母有点类似L_p范数，这样其中较大的值影响就会比较大)，增强了模型的泛化能力。a为归一化之前的神经元，b为归一化之后的神经元；N是卷积核的个数，也就是生成的FeatureMap的个数；k，α，β，n是超参数，论文中使用的值是k=2，n=5，α=0.0001，β=0.75。</p>
<p>池化采用了3*3，stride=2的池化单元进行最大池化操作，得到输出是 (55+2<em>0-3)/2 +1=27,这样96个通道分为一半之后48个，每组就是27\</em>27*48</p>
<p>其余卷积层同理也是采用相似的方式进行搭配。我们看全连接层</p>
<p>最左边那个全连接层FC6,其流程为全连接-&gt;ReLU-&gt;Dropout.</p>
<p>全连接的输入是6*6*256,使用 4096个6*6*256的卷积核进行卷积，得到(input_size + 2 <em> padding - kernel_size) / stride + 1=(6+2</em>0-6)/1+1=1也就是1*1*4096个神经元，其运算结果通过ReLU激活函数中。</p>
<p>同时该层为了防止过拟合，采取了Dropout的方法，在前文也提到过，随机断开全连接层某些神经元的连接，不激活某些神经元。</p>
<p>FC7同理。</p>
<p>输出层流程:全连接-&gt;softmax</p>
<p>全连接输入是4096个神经元，输出1000个神经元，对应1000个检测类别。而后运算结果通过softmax函数，输出1000个类别对应预测概率</p>
<p>可以估算总需要的参数数量，其方法如下:</p>
<p>对于卷积层，计算卷积核的参数数量(需要加上偏置参数)，对于全连接层，计算神经元乘以每个神经元的参数数量(还有偏置参数)</p>
<h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><p>个人感觉VGG的主要特点就是卷积层的叠加，形成VGG块。其与AlexNet对比如下</p>
<p><img src="https://s2.loli.net/2024/08/13/DbWBUXFZr6ujVIL.png" alt="image-20240813172237380"></p>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>残差神经网络(ResNet)属于深度学习模型的一种，其核心在于让网络的每一层不直接学习预期输出，而是学习与输入之间的残差关系。</p>
<p>其详细解析见<code>论文阅读</code>模块。因为在看相关文章的时候感觉大部分都是讲了how 和 what，而并没有讲why，也没有详细的数学证明，感觉很难受，所以还是去看了原论文看看有没有详细解释。</p>
<p>其基本原理是利用了一个叫做<code>残差块</code>的子网络。并且通过叠加残差块形成深度残差网络。</p>
<p><img src="https://s2.loli.net/2024/08/16/L6Wkmn21KxTBNEX.png" alt="image-20240816094800992"></p>
<p>其思想是，假设我们在一个多层神经网络模型中，有一个子网络，其函数用$H(x)$来表示，$x$是子网络的输出。而残差学习目的是调整这个子网络的参数，使其表达残差函数$F(x) = H(x)-x$。这样可以通过添加一个恒等映射的跳跃连接(叫做残差连接)，然后训练得到。</p>
<p>原始的ResNet研究中的残差块结构如图所示，其包含了两个3*3的卷积层和一个残差连接(其实是沿用了VGG的3*3卷积层设计)。因为串联了两个3*3的卷积层，所以就要求这2个卷积层的输入和输出形状一样，使得其可以相加。</p>
<p><img src="https://s2.loli.net/2024/08/16/DPntOV9W4pwime3.png" alt="image-20240816095317329"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">nn.Module</span>):</span>  <span class="comment">#@save</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_channels, num_channels,</span></span></span><br><span class="line"><span class="function"><span class="params">                 use_1x1conv=False, strides=<span class="number">1</span></span>):</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides) <span class="comment">#卷积块1</span></span><br><span class="line">        <span class="comment">#kernel_size=3,padding = 1,strides=1使得output_size=(input_size+2*1-3)/1 +1 = input_size</span></span><br><span class="line">        self.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment">#卷积块2 </span></span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)归一化处理</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        Y += X <span class="comment">#残差连接</span></span><br><span class="line">        <span class="keyword">return</span> F.relu(Y)</span><br></pre></td></tr></table></figure>
<p>残差块的实现如上所示。</p>
<p>ResNet的前两层和GoogLeNet一样，首先是输出通道数为64，步幅为2的7*7卷积层，然后是步幅为2的3*3最大汇聚层。但是ResNet在卷积层后添加了批量规范化层</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>接下来ResNet使用了4个由残差块组成的模块。</p>
<p>第一个模块的输出通道数和输入通道数一致</p>
<p>之后的每个模块在第一个残差块中将上一个模块的通道数翻倍，同时高和宽减半.</p>
<p>最后加入全局平均汇聚层，以及全连接输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet_block</span>(<span class="params">input_channels, num_channels, num_residuals,</span></span></span><br><span class="line"><span class="function"><span class="params">                 first_block=False</span>):</span></span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">            blk.append(Residual(input_channels, num_channels,</span><br><span class="line">                                use_1x1conv=<span class="literal">True</span>, strides=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(Residual(num_channels, num_channels))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line">b2 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">b3 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">b4 = nn.Sequential(*resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">b5 = nn.Sequential(*resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5,</span><br><span class="line">                    nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                    nn.Flatten(), nn.Linear(<span class="number">512</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<h2 id="Trainsfromer"><a href="#Trainsfromer" class="headerlink" title="Trainsfromer"></a>Trainsfromer</h2><h2 id="一些聚类算法"><a href="#一些聚类算法" class="headerlink" title="一些聚类算法"></a>一些聚类算法</h2><p>简单来说聚类就是将样本集$D = \{\mathbf{x_1} \dots,\mathbf{x_m} \}$ 划分成$k$个不相交的簇$\{C_l | l = 1,2,\dots,k\}$ ,两两不相交，所有并集结果为样本集。</p>
<p>我们希望得到的划分使得簇内相似性高，簇间相似性低。其性能度量分为两类，一种是将聚类结果与某个“参考模型”比较，称为外部指标。还有一种就是不利用任何参考模型，称为“内部指标”</p>
<p>对于有参考模型$C^<em> = \{C_1^</em>,C_2^<em>,\dots,C_s^</em>\}$的，我们可以对样本中的某个样本对$\mathbf{x_i},\mathbf{x_j}$，根据我们算法得到的聚类结果$C$以及参考模型$C^*$得到的结果分类分为四种情况:</p>
<ul>
<li>二者在$C$和$C^*$都归为一类，其结果总数记为$a$</li>
<li>二者在$C$中归为一类，$C^*$中不归为一类，其结果总数记为$b$</li>
<li>二者在$C^*$中归为一类，$C$中不归为一类，其结果总数记为$c$</li>
<li>二者在$C$和$C^*$都不归为一类，其结果总数记为$d$</li>
</ul>
<p>显然有$a+b+c+d = \frac{m(m-1)}{2}$</p>
<p>有如下指数进行衡量</p>
<ul>
<li>Jaccard指数</li>
</ul>
<script type="math/tex; mode=display">
JC = \frac{a}{a+b+c}</script><ul>
<li>FM指数</li>
</ul>
<script type="math/tex; mode=display">
FMI = \sqrt{\frac{a}{a+b}\frac{a}{a+c}}</script><ul>
<li>RAND指数</li>
</ul>
<script type="math/tex; mode=display">
RI = \frac{2*(a+d)}{m(m-1)}</script><p>上述指标在$[ 0,1]$区间，并且值越大越好。</p>
<p>对于簇划分结果$C = \{C_1,C_2,\dots,C_k\}$ 有</p>
<script type="math/tex; mode=display">
avg(C) = \frac{2}{|C|(|C|-1)} \sum_{1\leq i\leq j \leq |C|} dist(\mathbf{x_i},\mathbf{x_j}) \\
diam(C) = max_{1\leq i\leq j \leq |C|} dist(\mathbf{x_i},\mathbf{x_j}) \\
d_{min}(C_i,C_j) = min_{\mathbf{x_i} \in C_i,\mathbf{x_j} \in C_j} dist(\mathbf{x_i},\mathbf{x_j}) \\
d_{cen}(C_i,C_j) = dist(\mathbf{\mu}_i,\mathbf{\mu}_j)</script><p>$dist(<em>,</em>)$用于计算样本间距离，$\mathbf{\mu}$ 代表簇中心点 $\mathbf{\mu} = \frac{1}{|C|} \sum_{1\leq i\leq |C|} \mathbf{x}_i$ 。</p>
<p>$avg(C)$代表簇$C$内样本平均距离</p>
<p>$diam(C)$代表簇$C$内样本最远距离</p>
<p>$d_{min}(C_i,C_j)$代表簇$C_i,C_j$的最近样本间距离</p>
<p>$d_{cen}(C_i,C_j)$代表簇$C_i,C_j$的中心点间距离</p>
<p>$dist(<em>,</em>)$常用的是<code>闵可夫斯基距离</code>  (其实就是Lp范数)</p>
<script type="math/tex; mode=display">
dist_{mk}(\mathbf{x_i},\mathbf{x_j}) = \sqrt[p]{(\sum_{u=1} ^{n} |x_{iu}-x_{ju}| ^p)}</script><p>$p=2$时代表了欧几里得距离，$p=1$代表了曼哈顿距离。</p>
<h3 id="k-means算法"><a href="#k-means算法" class="headerlink" title="k-means算法"></a>k-means算法</h3><p>给定样本集$D = \{\mathbf{x_1} \dots,\mathbf{x_m} \}$,k-means算法针对聚类得到的簇划分$C = \{C_1,C_2,\dots,C_k\}$,最小化平方误差</p>
<script type="math/tex; mode=display">
E = \sum_{i=1} ^{k} \sum_{\mathbf{x} \in C_i} ||\mathbf{x}-\mathbf{\mu}_i||_2^2</script><p>简单来说就是最小化每个簇离其簇中心点的距离的和。</p>
<p>它很难最小化，是一个NP问题。K-means使用的是贪心策略，其算法如下所示。</p>
<p><img src="https://s2.loli.net/2024/08/17/CjZz2vSiaQoPRJm.png" alt="image-20240817164750691"></p>
<p>挺好理解的，就是首先初始化均值向量，然后对每个向量考察每个簇不断挑选离其最近的划入，然后更新均值向量，重复此过程。</p>
<p>但是个人感觉这种方法的准确率有点取决于初始化的那些初始化的均值向量的优劣？</p>
<h3 id="学习向量化-LVQ"><a href="#学习向量化-LVQ" class="headerlink" title="学习向量化(LVQ)"></a>学习向量化(LVQ)</h3><p>LVQ假设数据样本带有类别标记</p>
<p>对于样本集$D = \{(\mathbf{x_1},y_1),\dots,(\mathbf{x_m},y_m)\}$ ，,$\mathbf{x_i}$ 由$n$ 个属性描述，$y_i \in \mathcal{Y}$</p>
<p>LVQ的目标是学得一组$n$维原型向量$\{ \mathbf{p}_1,\mathbf{p}_2,\dots,\mathbf{p}_q\}$,每个原型向量代表一个聚类簇，簇标记$t_i \in \mathcal{Y}$</p>
<p>其算法如下</p>
<p><img src="https://s2.loli.net/2024/08/17/cbvFBxeA3UuE6lZ.png" alt="image-20240817172355331"></p>
<p>主要关键是6-10行，如果原型向量与挑选样本标记相同，则靠拢，否则远离。</p>
<h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p>引入是为了解决对序列信息的预测</p>
<script type="math/tex; mode=display">
x_t \sim P(x_t|x_{t-1},\dots,x_1)</script><p>对其有几种策略，一种是追求一定程度上的局部性，即认为只有最近的$\tau$个序列($x_{t-1},\dots,x_{t-\tau}(t&gt;\tau)$)是有用的。这种称为自回归模型</p>
<p>还有一种是保留对过去的所有总结$h_t$,并更新预测$\hat{x_t}$和总结$h_t$。$h_t$相当于对过往信息的一种汇总吧.即基于以下两个递推式。这种称为隐变量自回归模型。</p>
<script type="math/tex; mode=display">
\hat{x_t} = P(x_t|h_t)\\ 
h_t = g(h_{t-1},x_{t-1})</script><p>示意图如下</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240820161605107.png" alt="image-20240820161605107"></p>
<h1 id="西瓜书课后题选做"><a href="#西瓜书课后题选做" class="headerlink" title="西瓜书课后题选做"></a>西瓜书课后题选做</h1><p>并没有全部都做，这里挑了一些觉得有意思的题做了记录一下，主要是一些数学推导相关的题，因为比较直观。读的时候感觉这本书涉及到一些凸优化的东西，因为笔者对数学还是很感兴趣的，以后有空了可以再深入了解一下。</p>
<h2 id="一、绪论"><a href="#一、绪论" class="headerlink" title="一、绪论"></a>一、绪论</h2><p>1.4 题意是将其他性能度量取代”分类错误率”进行证明”没有免费的午餐定理”仍然成立</p>
<p>即将</p>
<script type="math/tex; mode=display">
E_{ote}(\mathcal L_a| X,f) = \sum_h\sum_{\mathbf{x} \in{\chi-X}} P(\mathbf{x}) \mathbb I(h(\mathbf{x}) \neq f(\mathbf{x}))P(h|X,\mathcal L_a)</script><p>中的指示函数$\mathbb I(*)$ 替换,证明方法类似，对于所有可能的均匀分布$f$求和。原先这里使用的是指示函数。对于二分类的话只要$\ell(h(\mathbf{x}) = f(\mathbf{x})) +\ell(h(\mathbf{x}) \neq f(\mathbf{x}))$仍为常数，我们仍然能对其进行展开</p>
<script type="math/tex; mode=display">
\sum_f E_{ote}(\mathcal L_a| X,f) = \sum_f\sum_h\sum_{\mathbf{x} \in{\chi-X}} P(\mathbf{x}) \ell(h(\mathbf{x}) , f(\mathbf{x}))P(h|X,\mathcal L_a) \\
=  \sum_{\mathbf{x} \in{\chi-X}} P(\mathbf{x})\sum_{h}P(h|X,\mathcal L_a) \sum_f\ell(h(\mathbf{x}) , f(\mathbf{x})) \\=\sum_{\mathbf{x} \in{\chi-X}} P(\mathbf{x})\sum_{h}P(h|X,\mathcal L_a)*2^{|\chi|-1}*A\\=2^{|\chi|-1}*A*\sum_{\mathbf{x} \in{\chi-X}}P(\mathbf{x})</script><p>仍然与学习算法$\mathcal L_a$无关</p>
<h1 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h1><h2 id="Deep-Residual-Learning-for-Image-Recognition"><a href="#Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="Deep Residual Learning for Image Recognition"></a>Deep Residual Learning for Image Recognition</h2><p>深度残差网络的论文。</p>
<p>作者在Introduction中提到在深层神经网络中，当网络开始收敛的时候会有退化问题：当网络层数增加的时候准确性趋于饱和(显然的增加层数可以一定程度提升准确性)，但是之后会迅速下降。作者提到这种问题并不是过拟合导致的。往一个合适的深度学习模型添加更多的层会引入更高的训练误差，如这个表格所示。作者统计对比了20层和56层的网络的训练误差和测试误差，均是56层的比较高。</p>
<p><img src="https://s2.loli.net/2024/08/16/qycCjJf1Q4XteLD.png" alt="image-20240816151416535"></p>
<p>作者认为这种退化表明并不是所有的系统都容易优化。作者构想了这样一个对比:假如有两个具有相同结构的深度学习模型A和B，他们前半部分完全一样，但是B相较于A在后面添加了一些恒等映射的层(相当于B只比A多加了这些恒等映射的层，其他均一致)。理论上来说，B不应该比A表现出更高的训练误差。但是实验显示我们现在使用的解决办法无法找到一个和这个构想的solution同等或更好的solution。</p>
<p>所以作者在论文中便是为了解决这个退化问题，引入了深度残差网络的框架。与其让这些层直接地去拟合一个潜在的映射，不如去让他们你和一个残差映射。用数学语言描述就是，原本这些layer拟合一个函数$H(\mathbf x)$,现在我们让其去拟合$F(\mathbf{x}) = H(\mathbf x)-\mathbf x$。这样原来的映射就相当于去拟合了$F(\mathbf{x}) +\mathbf{x}$ 。作者假定去拟合这样的残差映射比拟合原本的映射要更好优化。极端地来说，如果我们需要拟合的是一个恒等映射，那么这些非线性层拟合全零肯定比拟合恒等映射要容易很多。作者在ImageNet上取得了非常好的成效，并且是在ImageNet上面最深的神经网络。</p>
<p><img src="https://s2.loli.net/2024/08/16/S4iI8KzZFM9hEaN.png" alt=" "></p>
<p>作者认为，如果多个非线性层能很好地渐进拟合$H(\mathbf{x})$,那么它同样也能很好地去渐进拟合$H(\mathbf{x}) -\mathbf{x}$ 。所以与其期望叠加层数来拟合$H(\mathbf{x})$,不如让其去你和一个残差函数$F(\mathbf{x}) =H(\mathbf{x})-\mathbf{x}$ ,这样原函数就变成了$F(\mathbf{x}) +\mathbf{x}$ ,虽然两者都能渐进地估计所需的函数，但是二者的训练难度是不同的。</p>
<p>作者将残差块数学描述为</p>
<script type="math/tex; mode=display">
\mathbf{y} = F(\mathbf{x},\{\mathbf{W_i}\}) +\mathbf{x}</script><p>其中$\mathbf{x},\mathbf{y}$分别代表了这些层的输入和输出向量。函数$F(\mathbf{x},\{\mathbf{W_i}\})$表示需要学习的残差映射。在Figure2中就是$F = W_2\sigma(W_1\mathbf{x})$ ,其中$\sigma$代表了ReLU函数。其中$F$和$\mathbf{x}$的维度需要向等，不然就要添加一个线性投影$W_s$</p>
<script type="math/tex; mode=display">
\mathbf{y} = F(\mathbf{x},\{\mathbf{W_i}\}) +W_s\mathbf{x}</script><p>同时作者提到了$F$最好包括两到三层，更多层也是可以的。但是如果只有一层的话将会退化成$\mathbf{y} = W_1\mathbf{x}+\mathbf{x}$,将没有明显的优势。</p>
<p>作者描述了两种模型。一种是Plain Network(个人理解就是普通的CNN)。它主要是作为基准与残差网络进行对比。它主要是使用了VGG网络的想法。每层卷积层有3*3的卷积核。并遵循两个规则:1对于相同的输出特征图的size，layers有相同数量的fliters，并且2如果特征图的size减半，那么fliters的数量就翻倍，以保持每层的时间复杂度。这个模型比VGG网络复杂性要低很多，大概有 3.6 billion FLOPs，只有VGG-19的18%。</p>
<p>还有一种就是作者构想的Residual Network即残差网络。与plain Network不同的是添加了一些残差连接。当输入和输出维度相同的时候，identity shortcuts可以直接使用，如果不同的话有几种选择:一种是增加维度补0，还有一种就是上述的添加线性投影。</p>
<p>作者在每一个卷积层后都添加了批量归一化操作，使用256的小批量size进行随机梯度下降，学习率从0.1开始，每次误差停滞的时候除以十。模型经过60*10^4次的迭代训练，并且不使用dropout方法(之前整理过)</p>
<p><img src="https://s2.loli.net/2024/08/16/yL5aC4q7hBDYWSR.png" alt="image-20240816201241952"></p>
<h2 id="Trainsformer-Attention-Is-All-You-Need"><a href="#Trainsformer-Attention-Is-All-You-Need" class="headerlink" title="Trainsformer(Attention Is All You Need)"></a>Trainsformer(Attention Is All You Need)</h2><h2 id="TASNET"><a href="#TASNET" class="headerlink" title="TASNET"></a>TASNET</h2><h3 id="论文阅读-1"><a href="#论文阅读-1" class="headerlink" title="论文阅读"></a>论文阅读</h3><p>这里主要记录问题建模与网络设计，实验部分之后有需要再总结</p>
<p>作者在引言中提到，大多数方法想办法为每个多信号的时频表示构造一个mask，但对于语音分离来说或许并不是一个最优的方法。并且，时频上的分解会造成诸多问题(信号相位和幅度的解耦等)。作者采用了时域音频分离网络进行处理。</p>
<p>作者认为在时域上的分离问题可以建模成如下，我们有$C$个声源$s_1(t),\dots,s_c(t)$ 我们能够获取的是其混合</p>
<script type="math/tex; mode=display">
x(t) = \sum_{i=1} ^C s_i(t)</script><p>我们可以将这些音频样本分为$K$段，每段长为$L$，即$\mathbf{x_k} \in \mathbb{R}^{1\times L}$ ,所以可以表示为</p>
<script type="math/tex; mode=display">
\mathbf{x}_k = x(t)\\
\mathbf{s}_{i,k} = s_i(t)</script><p>其中$t\in [kL,(k+1)L ),k = 1,2,\dots,K$ 。这里为了表示$\mathbf{x}$，我们可以将其建模为若干基向量的线性组合形式，即</p>
<script type="math/tex; mode=display">
\mathbf{x} = \mathbf{wB}\\
\mathbf{s_i} = \mathbf{d_iB}</script><p>其中$\mathbf{B}$由$N$个长度为$L$的向量$\mathbf{b_1},\dots,\mathbf{b_N}$组成</p>
<p>其中有</p>
<script type="math/tex; mode=display">
\mathbf{w} = \sum_{i=1}^{C}\mathbf{d_i}</script><p>如果我们要对其进行分离，显然给其运算一个掩码MASK即可，即令</p>
<script type="math/tex; mode=display">
\mathbf{w} \odot \mathbf{m_i} = \mathbf{d_i}</script><p>整个结构分为三个部分，即<code>encoder</code>,<code>separation</code>以及<code>decoder</code>部分，示意如下</p>
<p><img src="https://s2.loli.net/2024/08/27/UaDRZcTIC1qV4jF.png" alt="image-20240827163301465"></p>
<p><code>encoder</code>部分所做的事是从$\mathbf{x}$中提取基向量，即</p>
<script type="math/tex; mode=display">
\mathbf{w_k} = ReLU(\mathbf{x_k} {\circledast}\mathbf{U}) \odot\sigma(\mathbf{x_k} {\circledast}\mathbf{V}) ,k = 1,2,\dots,K</script><p>其中${\circledast}$代表卷积运算，$\mathbf{x}_k \in \mathbb{R}^{1\times L},\mathbf{U} \in \mathbb{R}^{N\times L},\mathbf{V} \in \mathbb{R}^{N\times L}$ ，个人认为这个$\mathbf{U},\mathbf{V}$ 充当了类似卷积核的东西，从$\mathbf{x}_k$中提取特征从而得到基向量$\mathbf{w}_k$ </p>
<p>作者提到了 <code>empirically it performs significantly better than using only ReLU or Sigmoid in our system</code> ,这也是为什么一个采用了ReLU,一个采用了sigmod。不过只是说其empirically,并没有严格论述为什么这样会better。</p>
<p>因为考虑时序性以及记忆性的因素，分离部分采用的是LSTM网络，输入的是$K$段向量$\mathbf{w}_1,\dots,\mathbf{w}_K \in \mathbb R^{1\times N}$,而输出的即第$i$段对应掩码$\mathbf{m}_{i,1},\dots,\mathbf{m}_{i,K} \in \mathbb R^{1\times N}$</p>
<p>需要注意的是，其输入<script type="math/tex">\mathbf{w_i}</script>需要经过正则化，即</p>
<script type="math/tex; mode=display">
\hat{\mathbf{w}_k} =\frac{\mathbf{g}}{\sigma}\otimes(\mathbf{w}_k-\mu) +\mathbf{b}
\\
\mu = \frac{1}{N}\sum_{j=1} ^{N} \mathbf{w}_{k,j} ,\sigma = \sqrt{\frac{1}{N}\sum_{j=1}^N (\mathbf{w}_{k,j}-\mu)^2}</script><p>作者正则化参考的是这一篇文章<code>Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton, “Layer normalization,” arXiv preprint arXiv:1607.06450, 2016.</code>。如果没猜错的话应该是参考这个式子</p>
<p><img src="https://s2.loli.net/2024/08/27/OxiSV1rFeN9dDCo.png" alt="image-20240827165802860"></p>
<p>但是作者采用的是$\otimes$这个符号，不知道是想表达的是克罗内克积还是哈达玛积，笔者猜测应该是后者。笔者打算看一下<code>Layer normalization</code>这篇文章。</p>
<p>对于decoder模块，当我们经过separation模块从$\hat{\mathbf{W}}$得到$M_i = [\mathbf{m}_{i,1},\dots,\mathbf{m}_{i,K}] \in \mathbb{R}^{K\times N}$ 之后，我们就能计算</p>
<script type="math/tex; mode=display">
\mathbf{D}_i = \mathbf{W}\odot\mathbf{M}_i</script><p>注意这里作用的是未经正则化的$\mathbf{W}$ </p>
<p>进而根据$\mathbf{B}$获取原始声源</p>
<script type="math/tex; mode=display">
\mathbf{S}_i = \mathbf{D}_i\mathbf{B}</script><p>损失函数使用的是SI-SNR，公式如下</p>
<script type="math/tex; mode=display">
s_{target} = \frac{\langle \hat{s},s \rangle s}{ \Vert s\Vert ^2} \\
e_{noise} = \hat{s} - s_{target} \\
SISNR = 10\log_{10}\frac{\Vert s_{target} \Vert ^2}{\Vert e_{noise} \Vert ^2}</script><p>其中$\hat{s}$是评估信号，$s$是纯净信号，$\langle \hat{s} ,s\rangle$代表了元素成绩再求和，$\Vert s \Vert ^2$代表了L2范数</p>
<p>应该参考了这一篇paper，回头看看</p>
<p>2019_<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/8683855/">SDR–half-baked or well done?</a></p>
<h3 id="代码阅读"><a href="#代码阅读" class="headerlink" title="代码阅读"></a>代码阅读</h3><p>前文主要针对的是理论分析，下面记录一下代码实现部分</p>
<p>主要针对的是其模型构建以及训练过程</p>
<p>关于模型构建:</p>
<p>主要集中在<code>tasnet.py</code>中 ，和论文中一样，在<code>TasNet</code>类的<code>__init__</code>方法分别声明了类成员<code>encoder</code>，<code>separator</code>以及<code>decoder</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TasNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, L, N, hidden_size, num_layers,</span></span></span><br><span class="line"><span class="function"><span class="params">                 bidirectional=True, nspk=<span class="number">2</span></span>):</span></span><br><span class="line">        super(TasNet, self).__init__()</span><br><span class="line">        <span class="comment"># hyper-parameter</span></span><br><span class="line">        self.L, self.N = L, N</span><br><span class="line">        self.hidden_size, self.num_layers = hidden_size, num_layers</span><br><span class="line">        self.bidirectional = bidirectional</span><br><span class="line">        self.nspk = nspk</span><br><span class="line">        <span class="comment"># Components</span></span><br><span class="line">        self.encoder = Encoder(L, N)</span><br><span class="line">        self.separator = Separator(N, hidden_size, num_layers,</span><br><span class="line">                                   bidirectional=bidirectional, nspk=nspk)</span><br><span class="line">        self.decoder = Decoder(N, L)</span><br></pre></td></tr></table></figure>
<p>同时定义了前向传播函数,这里就是使用了<code>encoder</code>对<code>mixture</code>进行编码，然后借由<code>separator</code>获取<code>mask</code>，最后作用于<code>mixture_w</code>获得<code>source</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, mixture, mixture_lengths</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        mixture: [B, K, L]</span></span><br><span class="line"><span class="string">        mixture_lengths: [B]</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        est_source: [B, nspk, K, L]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    mixture_w, norm_coef = self.encoder(mixture)</span><br><span class="line">    est_mask = self.separator(mixture_w, mixture_lengths)</span><br><span class="line">    est_source = self.decoder(mixture_w, est_mask, norm_coef)</span><br><span class="line">    <span class="keyword">return</span> est_source</span><br></pre></td></tr></table></figure>
<p>模型主要就三个部件，<code>Encoder</code>，<code>Separator</code>以及<code>Decoder</code></p>
<p><code>Encoder</code>如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimation of the nonnegative mixture weight by a 1-D gated conv layer.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, L, N</span>):</span></span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        <span class="comment"># hyper-parameter</span></span><br><span class="line">        self.L = L</span><br><span class="line">        self.N = N</span><br><span class="line">        <span class="comment"># Components</span></span><br><span class="line">        <span class="comment"># Maybe we can impl 1-D conv by nn.Linear()?</span></span><br><span class="line">        self.conv1d_U = nn.Conv1d(L, N, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>) <span class="comment">#论文中的一维卷积U,V,kernel_size=1，每次卷积卷1*L,卷N次生成的N*1</span></span><br><span class="line">        self.conv1d_V = nn.Conv1d(L, N, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>) <span class="comment"># 同理</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, mixture</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mixture: [B, K, L] #这里大小B*K*L的B应该是每个batch大小</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            mixture_w: [B, K, N]</span></span><br><span class="line"><span class="string">            norm_coef: [B, K, 1]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, K, L = mixture.size()</span><br><span class="line">        <span class="comment"># L2 Norm along L axis</span></span><br><span class="line">        norm_coef = torch.norm(mixture, p=<span class="number">2</span>, dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># B x K x 1 计算L上的L2范数</span></span><br><span class="line">        norm_mixture = mixture / (norm_coef + EPS) <span class="comment"># B x K x L 除以范数，进行归一化，同时EPS防止除0</span></span><br><span class="line">        <span class="comment"># 1-D gated conv</span></span><br><span class="line">        norm_mixture = torch.unsqueeze(norm_mixture.view(<span class="number">-1</span>, L), <span class="number">2</span>)  <span class="comment"># B*K x L x 1 维度进行调整，感觉就是调整为若干L x 1的向量组合，方便卷积，最后再重整回来</span></span><br><span class="line">        conv = F.relu(self.conv1d_U(norm_mixture))         <span class="comment"># B*K x N x 1 #一个过ReLU函数</span></span><br><span class="line">        gate = torch.sigmoid(self.conv1d_V(norm_mixture))  <span class="comment"># B*K x N x 1 #一个过sigmoid函数</span></span><br><span class="line">        mixture_w = conv * gate  <span class="comment"># B*K x N x 1</span></span><br><span class="line">        mixture_w = mixture_w.view(B, K, self.N) <span class="comment"># B x K x N</span></span><br><span class="line">        <span class="keyword">return</span> mixture_w, norm_coef</span><br></pre></td></tr></table></figure>
<p>对于分离的模块，其代码及注释如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Separator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Estimation of source masks</span></span><br><span class="line"><span class="string">    TODO: 1. normlization described in paper </span></span><br><span class="line"><span class="string">          2. LSTM with skip connection</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, N, hidden_size, num_layers, bidirectional=True, nspk=<span class="number">2</span></span>):</span></span><br><span class="line">        super(Separator, self).__init__()</span><br><span class="line">        <span class="comment"># hyper-parameter</span></span><br><span class="line">        self.N = N</span><br><span class="line">        self.hidden_size = hidden_size <span class="comment">#隐含层维度</span></span><br><span class="line">        self.num_layers = num_layers <span class="comment">#一般是单层LSTM</span></span><br><span class="line">        self.bidirectional = bidirectional</span><br><span class="line">        self.nspk = nspk <span class="comment">#应该是说话人数</span></span><br><span class="line">        <span class="comment"># Components</span></span><br><span class="line">        self.layer_norm = nn.LayerNorm(N) <span class="comment">#标准化，作者应该用了这个来代替paper里面的normlization</span></span><br><span class="line">        self.rnn = nn.LSTM(N, hidden_size, num_layers,</span><br><span class="line">                           batch_first=<span class="literal">True</span>, <span class="comment">#第一个维度是batch_size</span></span><br><span class="line">                           bidirectional=bidirectional) <span class="comment">#双向LSTM</span></span><br><span class="line">        fc_in_dim = hidden_size * <span class="number">2</span> <span class="keyword">if</span> bidirectional <span class="keyword">else</span> hidden_size</span><br><span class="line">        self.fc = nn.Linear(fc_in_dim, nspk * N) <span class="comment">#全连接层</span></span><br><span class="line">        <span class="comment">### To impl LSTM with skip connection</span></span><br><span class="line">        <span class="comment"># self.rnn = nn.ModuleList()</span></span><br><span class="line">        <span class="comment"># self.rnn += [nn.LSTM(N, hidden_size, num_layers=1,</span></span><br><span class="line">        <span class="comment">#                      batch_first=True,</span></span><br><span class="line">        <span class="comment">#                      bidirectional=bidirectional)]</span></span><br><span class="line">        <span class="comment"># for l in range(1, num_layers):</span></span><br><span class="line">        <span class="comment">#     self.rnn += [nn.LSTM(hidden_size, hidden_size, num_layers=1,</span></span><br><span class="line">        <span class="comment">#                          batch_first=True,</span></span><br><span class="line">        <span class="comment">#                          bidirectional=bidirectional)]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, mixture_w, mixture_lengths</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mixture_w: [B, K, N], padded</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            est_mask: [B, K, nspk, N]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, K, N = mixture_w.size()</span><br><span class="line">        <span class="comment"># layer norm</span></span><br><span class="line">        norm_mixture_w = self.layer_norm(mixture_w) <span class="comment">#首先经过normlization</span></span><br><span class="line">        <span class="comment"># LSTM</span></span><br><span class="line">        total_length = norm_mixture_w.size(<span class="number">1</span>)  <span class="comment"># get the max sequence length</span></span><br><span class="line">        packed_input = pack_padded_sequence(norm_mixture_w, mixture_lengths,</span><br><span class="line">                                            batch_first=<span class="literal">True</span>)<span class="comment"># 压紧数据</span></span><br><span class="line">        packed_output, hidden = self.rnn(packed_input)<span class="comment">#经过RNN，这里就是init定义的LSTM</span></span><br><span class="line">        output, _ = pad_packed_sequence(packed_output, <span class="comment">#解压数据</span></span><br><span class="line">                                        batch_first=<span class="literal">True</span>,</span><br><span class="line">                                        total_length=total_length)</span><br><span class="line">        <span class="comment"># fc</span></span><br><span class="line">        score = self.fc(output)  <span class="comment"># B x K x nspk*N #经过全连接层，将得到的特征空间映射样本标记空间</span></span><br><span class="line">        score = score.view(B, K, self.nspk, N)</span><br><span class="line">        <span class="comment"># softmax</span></span><br><span class="line">        est_mask = F.softmax(score, dim=<span class="number">2</span>) <span class="comment">#过一个softmax</span></span><br><span class="line">        <span class="keyword">return</span> est_mask</span><br></pre></td></tr></table></figure>
<p><code>Decoder</code>类如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, N, L</span>):</span></span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        <span class="comment"># hyper-parameter</span></span><br><span class="line">        self.N, self.L = N, L</span><br><span class="line">        <span class="comment"># Components</span></span><br><span class="line">        self.basis_signals = nn.Linear(N, L, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, mixture_w, est_mask, norm_coef</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mixture_w: [B, K, N]</span></span><br><span class="line"><span class="string">            est_mask: [B, K, nspk, N]</span></span><br><span class="line"><span class="string">            norm_coef: [B, K, 1]</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            est_source: [B, nspk, K, L]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># D = W * M</span></span><br><span class="line">        source_w = torch.unsqueeze(mixture_w, <span class="number">2</span>) * est_mask  <span class="comment"># B x K x nspk x N</span></span><br><span class="line">        <span class="comment"># S = DB</span></span><br><span class="line">        est_source = self.basis_signals(source_w)  <span class="comment"># B x K x nspk x L</span></span><br><span class="line">        <span class="comment"># reverse L2 norm</span></span><br><span class="line">        norm_coef = torch.unsqueeze(norm_coef, <span class="number">2</span>)  <span class="comment"># B x K x 1 x1</span></span><br><span class="line">        est_source = est_source * norm_coef  <span class="comment"># B x K x nspk x L</span></span><br><span class="line">        est_source = est_source.permute((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)).contiguous() <span class="comment"># B x nspk x K x L</span></span><br><span class="line">        <span class="keyword">return</span> est_source</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>之后main函数主要是测试用</p>
<h2 id="Conv-TasNet"><a href="#Conv-TasNet" class="headerlink" title="Conv-TasNet"></a>Conv-TasNet</h2><p>还是TasNet那个作者写的，主要区别就是不采用LSTM了，而是用了类似TCN的卷积的结构(TCN下面有整理)。作者提到，在原始的TasNet中使用LSTM限制了适用性。首先是在编码器中选择较小的内核大小(即语音帧长)，增加了编码器输出的长度，这使得LSTM的训练难以管理。其次，深度LSTM网络中大量的参数显著增加了其计算成本。这样难以在一些小型的穿戴听力设备中使用。第三则是由LSTM网络的长时间依赖性引起的，这常常导致分离精度不一致，例如，当改变混合的起始点时。</p>
<p>还是和Tasnet差不多，我们的建模就是从混合波形$x(t) \in \mathbb{R}^{1\times T}$中估计出若干源信号 $s_i(t) \in \mathbb{R} ^{1\times T}$</p>
<script type="math/tex; mode=display">
x(t) = \sum_{i=1} ^C s_i(t)</script><p>还是一样的把输入分为长度为$L$的帧，即$x_k \in \mathbb{R} ^{1\times L}$,编码模块采用了一维卷积运算</p>
<script type="math/tex; mode=display">
w = \mathcal{H}(xU^{T})</script><p>其中$U \in \mathbb{R}^{N\times L}$包含了$N$个向量(编码基函数)，$H$是可选的激活函数,而解码器可以表示为</p>
<script type="math/tex; mode=display">
\hat{x} = wV</script><p>其中$\hat{x} \in \mathbb{R}^{1\times L}$是重建的$x$，而$V \in \mathbb{R} ^{N\times L}$ 是解码器的基函数</p>
<p>而分离的过程也和TasNet一样，将mask应用在混合表示$w$上，最后乘以解码器</p>
<script type="math/tex; mode=display">
d_i = w\odot m_i \\
\hat{s_i} = d_iV</script><p>主要作更改的是分离模块，没有采用LSTM，而是一种类似于TCN的设计</p>
<p><img src="https://s2.loli.net/2024/08/28/48V9RuSnFexX2hw.png" alt="image-20240828211427094"></p>
<p>同时，作者使用深度可分离卷积$S_conv(<em>)$来代替标准卷积,深度可分离卷积算子由两个连续运算(depthwise convolution,即$D_conv(</em>)$)以及(pointwise convolution，即$1\times 1-conv(*)$)组成 </p>
<script type="math/tex; mode=display">
S\_conv(\mathbf{Y},\mathbf{K},\mathbf{L}) = D\_conv(\mathbf{Y},\mathbf{K})\circledast\mathbf{L} \\
D\_conv(\mathbf{Y},\mathbf{K}) = concat(\mathbf{y}_j\circledast\mathbf{k}_j),j=1,\dots,N</script><p>其中$\mathbf{Y} \in \R ^{G\times M}$为输入，$\mathbf{K} \in \R ^{G\times P}$是大小为$P$的卷积核，$\mathbf{y}_j \in \R^{1\times M}$以及$\mathbf{k}_j \in \R^{1\times P}$为矩阵$\mathbf{Y}$以及$\mathbf{K}$的行，$\mathbf{L}$为大小为1的卷积核，$\circledast$代表卷积运算。其一共有$G\times P+G\times H$个参数，而标准卷积$\hat{\mathbf{K}}\in \R ^{G\times H\times P}$则有$G\times H\times P$个参数，其模型大小显著降低</p>
<h2 id="TCN的想法"><a href="#TCN的想法" class="headerlink" title="TCN的想法"></a>TCN的想法</h2><p>RNN在序列问题上有良好表现，但其并不能并行运算，只能一次处理一个时间步长。而TCN借鉴了CNN的模型，以其为基础，提出了下列改进:<code>适用序列模型：因果卷积</code>,<code>记忆历史：空洞卷积/膨胀卷积</code>以及<code>残差模块</code></p>
<p>首先是因果卷积。对于序列问题其可转化为根据$x_1,x_2,\dots,x_t$预测$y_1,y_2,\dots,y_t$。给定滤波器$F = (f_1,f_2,\dots,f_K)$以及序列$X = (x_1,x_2,\dots,x_T)$，则其在$x_t$处的因果卷积为</p>
<script type="math/tex; mode=display">
(F *X)_{(x_t)}  = \sum_{k=1} ^Kf_kx_{t-K-k}</script><p>示意如下图所示</p>
<p><img src="https://s2.loli.net/2024/08/28/Uy693GSHl1VW5c2.png" alt="image-20240828155529170"></p>
<p>对于上一层时刻$t$,其只依赖下一层时刻$t$及其之前的值，其不能看到未来的数据，是一种单向的结构。并且它没有循环连接的结构，所以训练起来比循环神经网络(RNN)更快。</p>
<p>但是这里有一个问题，如果我们想要某个output(比如$y_t$)尽量获取多一点之前序列的信息，就只能尽可能地去叠加隐藏层。在这个图中，一个输出层期望采集输入层的5个时间步，则需要3个隐藏层。如果在想扩展采集更早的时间步，则只能再叠隐藏层。</p>
<p>所以引入了<code>膨胀卷积/空洞卷积(Dilated Convolution)</code>的想法。空洞卷积意味着我们在卷积的过程中可能会隔几个取样一次，示意如下</p>
<p><img src="https://s2.loli.net/2024/08/28/ra2sS5tcbuIgJzd.png" alt="image-20240828160850411"></p>
<p>其每一层的$d$就代表了<code>Dilatation rate</code>，通俗来说就是到底隔多少个取样一次。其在$x_t$处的Dilatation rate = $d$的空洞卷积可表示为</p>
<script type="math/tex; mode=display">
(F*_dX)_{(x_t)} = \sum_{k=1} ^K f_kx_{t-(K-k)d}</script><p>一般而言随着层数增加，$d$以2的指数级增长，比如上图采取的就是1,2,4(很好理解，因为这样确保了最上面的output $\hat{y_k}$能够最快且最满地提取到input的信息，也就是说，这样使得最上层$\hat{y_t}$所能提取的最长的input信息$L$M满足$L\sim 2^h$) </p>
<p>最后是残差连接</p>
<p>通常残差连接可以描述为,对于我们设置的一系列变换$\mathcal{F}$，可以通过残差连接将其表示为</p>
<script type="math/tex; mode=display">
o = Activation(\mathbf{x}+\mathcal{F}(\mathbf{x}))</script><p>一个TCN的残差block如图所示</p>
<p><img src="https://s2.loli.net/2024/08/28/H8zL5Dkef4NqpSW.png" alt="image-20240828162907988"></p>
<p>对于输入$\hat{\mathbf{z}}^{(i-1)}$，一方面其经过左边变换(dilated causal conv-&gt;weightNorm-&gt;ReLU-&gt;Dropout等一系列)，另一方面经过1x1卷积(或者不经过)和左边的输出进行连接</p>
<p><img src="https://s2.loli.net/2024/08/28/maqiYs5nTNXRU46.png" alt="image-20240828163345788"></p>
<p>综上，使用pytorch实现TCN的代码如下所示(作者<a target="_blank" rel="noopener" href="https://github.com/locuslab/TCN/blob/master/TCN/tcn.py">github.com</a>)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个1-D卷积层的截断模块，主要用于去除sequence右边的padding</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Crop1d</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, crop_size</span>):</span></span><br><span class="line">        super(Crop1d, self).__init__()</span><br><span class="line">        self.crop_size = crop_size  <span class="comment"># 输入需要被裁剪的序列长度</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, sequence</span>):</span></span><br><span class="line">        <span class="keyword">return</span> sequence[:, :, :-self.crop_size].contiguous()  <span class="comment"># 裁剪输入，返回截断后的序列</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># 定义用于时间序列预测的1-D卷积神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TemporalBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=<span class="number">0.2</span></span>):</span></span><br><span class="line">        super(TemporalBlock, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义两个卷积层，对权重进行规范化</span></span><br><span class="line">        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,</span><br><span class="line">                                           stride=stride, padding=padding, dilation=dilation))  <span class="comment"># 第一层卷积层</span></span><br><span class="line">        self.crop1 = Crop1d(padding)  <span class="comment"># 第一层卷积层后面的截取模块</span></span><br><span class="line">        self.relu1 = nn.ReLU()  <span class="comment"># 第一层卷积的激活函数</span></span><br><span class="line">        self.dropout1 = nn.Dropout(dropout)  <span class="comment"># 第一层卷积的dropout层</span></span><br><span class="line"></span><br><span class="line">        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,</span><br><span class="line">                                           stride=stride, padding=padding, dilation=dilation))  <span class="comment"># 第二层卷积层</span></span><br><span class="line">        self.crop2 = Crop1d(padding)  <span class="comment"># 第二层卷积层后面的截取模块</span></span><br><span class="line">        self.relu2 = nn.ReLU()  <span class="comment"># 第二层卷积的激活函数</span></span><br><span class="line">        self.dropout2 = nn.Dropout(dropout)  <span class="comment"># 第二层卷积的dropout层</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将两个卷积层、截取模块、激活函数和dropout层按照顺序放入一个新的模型中，并作为TimeBlock的网络模型</span></span><br><span class="line">        self.net = nn.Sequential(self.conv1, self.crop1, self.relu1, self.dropout1,</span><br><span class="line">                                 self.conv2, self.crop2, self.relu2, self.dropout2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果输入和输出的特征通道数不同，定义1x1的卷积层进行通道数的转换</span></span><br><span class="line">        self.downsample = nn.Conv1d(n_inputs, n_outputs, <span class="number">1</span>) <span class="keyword">if</span> n_inputs != n_outputs <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.init_weights()  <span class="comment"># 初始化模型参数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对模型的参数进行初始化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.conv1.weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">        self.conv2.weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.downsample.weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播计算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.net(x)  <span class="comment"># 对输入的x进行卷积操作，并通过relu和dropout层进行处理</span></span><br><span class="line">        res_part = x <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> self.downsample(</span><br><span class="line">            x)  <span class="comment"># 如果输出的通道数和输入的通道数不一致，则需要定义一个1x1的卷积层进行通道数转换，这里将res_part指定为输入x或转换后的输出结果。</span></span><br><span class="line">        res = out + res_part  <span class="comment"># 使用相加的方式进行残差连接</span></span><br><span class="line">        <span class="keyword">return</span> self.relu(res)  <span class="comment"># 通过激活函数处理后返回</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># 定义用于时间序列预测的卷积神经网络模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TemporalConvNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># num_inputs是一个列表，其长度代表TemporalBlock的层数，值表示输入序列的通道数（特征维度）。</span></span><br><span class="line">    <span class="comment"># out_channels是一个列表，其长度代表TemporalBlock的层数，值表示每个TemporalBlock中输出的通道数（特征维度）。</span></span><br><span class="line">    <span class="comment"># kernel_size是卷积核的大小，默认为2。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size=<span class="number">2</span>, dropout=<span class="number">0.2</span></span>):</span></span><br><span class="line">        super(TemporalConvNet, self).__init__()</span><br><span class="line">        layers = []</span><br><span class="line">        num_levels = len(out_channels)</span><br><span class="line">        <span class="comment"># 使用for循环，定义多个TemporalBlock模块，并按序添加到网络结构中</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_levels):</span><br><span class="line">            dilation_size = <span class="number">2</span> ** i  <span class="comment"># 逐层dilation以2的指数增长</span></span><br><span class="line">            in_channel = in_channels[i]</span><br><span class="line">            out_channel = out_channels[i]</span><br><span class="line">            layers += [TemporalBlock(in_channel, out_channel, kernel_size, stride=<span class="number">1</span>, dilation=dilation_size,</span><br><span class="line">                                     padding=(kernel_size - <span class="number">1</span>) * dilation_size, dropout=dropout)]</span><br><span class="line">        self.network = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型前向计算，按顺序执行各模块的前向计算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.network(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>一篇讲Normalization的paper，之前在TasNet里那个作者使用过其中的一个例子(虽然代码实现的时候还是只用了torch的库函数，并没有自己实现)</p>
<p>这篇paper主要讲的是一个针对不同神经网络模型提出的训练提速的normalization方法，和batch normalization(好像是google的一篇文章，回头看看)不同，这个方法直接对输进隐藏层的神经元的input进行normalization，所以并不引入training case之间的依赖。作者证明了这个方法对一些RNN模型work得非常好</p>
<p>这里顺带总结一下batch normalization</p>
<p>一般我们期望的数据满足<code>独立同分布</code>这个条件，所以对数据进行预处理的时候我们通常都会进行<code>白化</code>操作，主要目的是</p>
<ul>
<li>去除特征间的相关性</li>
<li>让所有特征具有相同的均值和方差</li>
</ul>
<p><code>Internal Covariate Shift</code>(简称ICS)现象参考<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/38102762/answer/85238569">(99+ 封私信 / 80 条消息) 深度学习中 Batch Normalization为什么效果好？ - 知乎 (zhihu.com)</a> 这个回答。它会导致几个问题，一个是上层参数需要不断适应新的输入数据分布，降低学习速度，一个是下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止，还有便是每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</p>
<p>一般对于神经元接收的向量及其运算</p>
<script type="math/tex; mode=display">
\mathbf{x} = (x_1,\dots,x_d) \\
y = f(\mathbf{x})</script><p>$\mathbf{x}$的分布可能相差很大，所以需要进行白化。一般通用的操作就是</p>
<script type="math/tex; mode=display">
h = f(\mathbf{g}\frac{\mathbf{x}-\mu}{\sigma}+\mathbf{b})</script><p>其中$\mu$是平移参数，$\sigma$是缩放参数，而$\mathbf{b}$是再平移参数，$\mathbf{g}$是再缩放参数。</p>
<p>这样实际上是先将数据变成均值为0，方差为1的标准分布，然后再将其缩放成均值为$\mathbf{b}$,方差为$\mathbf{g}^2$的分布。</p>
<p>为什么不直接使用标准分布，还要再变一次？是为了<strong>保证模型的表达能力不因为规范化而下降</strong></p>
<p>通俗来说，下层神经元所学习的一些变化，如果再交给上层时被直接规范化的话，会一定程度上削弱下层神经元的学习结果</p>
<p>并且$\mathbf{g}$和$\mathbf{b}$是可学习的，这样这个Normalization层可以去学习如果适应下层神经元的变化。还有一点就是我们知道在每一层会经过一个激活函数，使得神经网络有了非线性计算的能力，如果我们直接将其规范化为标准分布，则可能会使得被激活的神经元变少，降低了神经网络的表达能力。</p>
<p>但是这样的Normalization变换也并不是严格的同分布，只是将其映射到了一个确定的区间范围</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>主要是针对输入的每一个维度$x_i$进行规范化，其使用的均值和方差如下</p>
<script type="math/tex; mode=display">
\mu_i = \frac{1}{M} \sum x_i \\
\sigma_i = \sqrt {\frac{1}{M}\sum(x_i-\mu_i)^2+\epsilon}</script><p>其中$M$是mini-batch大小。</p>
<p>细想就可以知道，这样的话我们期望的是，每个mini-batch的相应维度$x_i$分布最好和整个数据的分布是同分布(这就要求mini-batch尽量大，并且shuffle尽量多一点)，不然会增加训练难度</p>
<h3 id="layer-Normalization"><a href="#layer-Normalization" class="headerlink" title="layer Normalization"></a>layer Normalization</h3><p>这是一个横向的规范化，通俗来说就是每一层的所有维度(而batch normalization针对的是某个维度的一个batch)</p>
<script type="math/tex; mode=display">
\mu = \sum_i x_i\\
\sigma = \sqrt{\sum_i(x_i-\mu) ^2+\epsilon}</script><p>其中$i$对这一层所有输入神经元进行枚举，所有输入共享一个规范化变换。</p>
<p>它针对的是单个训练样本。仔细一想可以知道，这样要求期望的输入的每个维度的贡献最好差不多，否则会降低模型的表达能力。所以对于RNN，自然语言处理等比较适用</p>
<h3 id="Weight-Normalization"><a href="#Weight-Normalization" class="headerlink" title="Weight Normalization"></a>Weight Normalization</h3><p>与BN和LY的思路不同，WN不作用于输入的$\mathbf{x}$，而是对与神经元之间的连线权重$\mathbf{w}$进行规范(感觉挺鸡肋的U1S1)</p>
<p>将权重向量分解为单位向量乘以向量模长的形式</p>
<script type="math/tex; mode=display">
\mathbf{w} = g*\hat{\mathbf{v}} = g*\frac{\mathbf{v}}{\Vert \mathbf{v} \Vert}</script><p>事实上对于一个输入$\mathbf{x}$，对其进行WN变换则有</p>
<script type="math/tex; mode=display">
f_{\mathbf{w}}(WN(\mathbf{x})) = \mathbf{w}*WN(\mathbf{x}) = g*\frac{\mathbf{v}}{\Vert \mathbf{v} \Vert} *\mathbf{x} = f_{\mathbf{v}}(g*\frac{\mathbf{x}}{\Vert \mathbf{v} \Vert})</script><p>就是将原来的权重$\mathbf{w}$进行规整化，将其变换到单位向量$\mathbf{v}$上，然后对于$\mathbf{x}$进行相应的放缩</p>
<h2 id="Spex"><a href="#Spex" class="headerlink" title="Spex"></a>Spex</h2><p>作者提到，这个模型的一个motivation是人对声音分离的<code>bottom-up</code>以及<code>top-down</code>机制。对于<code>bottom up</code>，作者举了一个例子，就像一声突然的爆炸声会吸引你的注意力，而<code>top-down</code>就类似人在机场里面会专注于听广播一样，是一种自上而下的attention(或者说 focus)。作者设计了一个<code>speaker encoder</code> 来实现这种机制。</p>
<p>作者采取的是TasNet那种time domain的角度去解决分离，和tasnet一样，为了避免相位估计等问题。</p>
<p>由于涉及到多个模块，作者并不单独训练某个模块，而是将其作为一个整体来训练，整体的loss就是各个模块loss的加权和</p>
<p>同时作者还提出了一个多时间尺度的encoding 和decoding，为了提高声音质量。</p>
<p>整体的架构如下图所示，主要分为了4个组件</p>
<p><img src="https://s2.loli.net/2024/09/11/rkXT6UNyxMgZweW.png" alt="image-20240911191706197"></p>
<p>其中<code>Speaker encoder</code>将说话人进行一个embedding，提取说话人的特征。而<code>Speech encoder</code>将混合音频encode成一个频谱或类频谱的特征表示。然后<code>Speaker Extractor</code>模块估计出让特定说话人通过的一个掩码表示，和<code>Speech encoder</code>得到的<code>embedding  Coefficient</code>做一个掩码，最后<code>Speech decoder</code>模块将掩码过后的频谱或者类频谱表示调制成time domain的speech</p>
<p>一段采样了$T$段的声音讯号$y(t)$可以表示成所要分离的目标说话人讯号$s(t)$和若干个background noise的mix</p>
<p>,即</p>
<script type="math/tex; mode=display">
y(t) = s(t) +\sum_{i=1} ^Ib(t),t=1,\dots T</script><p>总体设计如下</p>
<p><img src="https://s2.loli.net/2024/09/11/F2d6ZUMPuob1Kmz.png" alt="image-20240911200712343"></p>
<h3 id="Speaker-encoder"><a href="#Speaker-encoder" class="headerlink" title="Speaker encoder"></a>Speaker encoder</h3><p>抽象成一个编码器$g(*)$，进行一个speaker 的特征提取$g(x)$ .在文本无关的语音识别中，经典的方式是将其表示成一个固定长度的向量，比如i-vector,x-vector,还有其他的 (PS:这里回头想详细看一下这些方案是如何进行一个特征提取的),进行一个声纹的表示。主要使用的是双向长短期记忆(BLSTM)</p>
<p>在一些工作中这些encoder是单独train的，还有一些工作中这些encoder是和extract一起train的，但是只是计算了extracted 和clean speeches之间的loss(如果我没理解错的话作者应该想表达的是这些jointly train的模型并没有单独重视这些encoder(比如额外计算loss等)，只是一个副产物.但是u1s1感觉有点。。。)</p>
<p>对于计算loss，作者采取了将speaker classification的交叉熵和说话人提取的提取语音与清晰语音之间的信号重构损失进行加权</p>
<h3 id="Speech-encoder"><a href="#Speech-encoder" class="headerlink" title="Speech encoder"></a>Speech encoder</h3><p>在频域方法中，通过应用傅里叶变换，语音信号被分解成一个交替表示，拥有属性正弦和余弦。类似地，在时域方法中，我们可以考虑卷积层中的滤波器作为基函数，类似于频域中的正弦和余弦。</p>
<p>对于时域的编码，和傅里叶变换之后的编码对比，其优点在于可以不用分别处理实部和虚部，并且基函数不是预先定义为正弦或余弦，而是可以通过数据进行训练。</p>
<p>一个input的mixture speech表示为$y(t) \in \mathbb{R}^{1\times T}$</p>
<p>在encode方面，主要用1-D CNN进行一个特征提取。并且作者还进行了多时间尺度的一个speech embedding，主要分为了$L1(short),L2(middle),L3(long)$ </p>
<p>同时为了将这些不同时间尺度的embedding给concatenate，需要通过保持相同的步长$\frac{L_1}{2}$来align他们</p>
<p>在不同长度尺度的embedding coefficients可以表示为</p>
<script type="math/tex; mode=display">
E_{i,k} = ReLU(y_{i,k}U_i),k=1\dots,K;i=1,2,3</script><p>其中$K=\frac{2(T-L_1)}{L1}+1$,$y_{i,k}\in \mathbb{R}^{1\times L_i}$是输入$y(t)$的一个shift形成的窗口(很形象，就是不断地移动)</p>
<h3 id="Speaker-Extractor"><a href="#Speaker-Extractor" class="headerlink" title="Speaker Extractor"></a>Speaker Extractor</h3><p>作者提到了常用的语音分离滤波模型<code>ideal binary mask (IBM)</code> ,<code>ideal ratio mask (IRM)</code> ,<code>ideal amplitude mask (IAM)</code>,<code>wiener-filter like mask (WFM)</code>以及 <code>phase sensitive mask (PSM)</code> （只知道IBM，那篇在还看着)</p>
<p>这里是对多个时间尺度分别mask的</p>
<script type="math/tex; mode=display">
S_i = M_i\otimes E_i\\=f(E,g(x))\otimes E_i</script><p>$f(<em>)$代表一个extract function，$g(</em>)$代表encoder function，$E$就是之前三个时间尺度上的speech encoder的一个concatenate，也就是$E = [E_1E_2E_3] \in \mathbb{R}^{K\times3N}$</p>
<h3 id="Speech-Decoder"><a href="#Speech-Decoder" class="headerlink" title="Speech Decoder"></a>Speech Decoder</h3><p>对三个尺度上的mask的$S_i$用$V_i\in \mathbb{R}^{N\times L_i}$的解码基进行一个去卷积过程。译码器基由训练过程中学会的滤波器组成，就像傅里叶基由正弦和余弦函数组成一样</p>
<h3 id="train"><a href="#train" class="headerlink" title="train"></a>train</h3><p>因为有三个时间尺度，所以计算SI-SDR的时候用三者的加权平均</p>
<script type="math/tex; mode=display">
J_1 = −[(1 −α −β)ρ(s_1,s) + αρ(s_2,s) + βρ(s_3,s)]</script><p>$s_i$是在该时间尺度上reconstruct完的信号，$s$是clean的信号</p>
<p>并且在speaker encoder的时候还涉及到一个 speaker classification的 交叉熵loss计算</p>
<script type="math/tex; mode=display">
J_2 = -\sum_{i=1} ^ {N_s}p_ilog(\hat{p_i})</script><p>其中$N_s$是在speaker classification中的说话者数。</p>
<p>总的loss</p>
<script type="math/tex; mode=display">
J = (1 −γ)J_1 + γJ_2</script><p>Q:  这样直接加权是合理的吗(量级之类的，如果但从$\gamma$进行调超参是否有点麻烦。假如某一个loss量级明显大于另一个，感觉会进行一个退化)，$J_1$和$J_2$ 是否冲突？</p>
<p>帕累托优化</p>
<h2 id="Spex-1"><a href="#Spex-1" class="headerlink" title="Spex+"></a>Spex+</h2><p>和Spex的改进与区别？</p>
<h2 id="Multi-resolution-speech-analysis-for-automatic-speech-recognition-using-deep-neural-networks-Experiments-on-TIMIT"><a href="#Multi-resolution-speech-analysis-for-automatic-speech-recognition-using-deep-neural-networks-Experiments-on-TIMIT" class="headerlink" title="Multi-resolution speech analysis for automatic speech recognition using deep neural networks: Experiments on TIMIT"></a>Multi-resolution speech analysis for automatic speech recognition using deep neural networks: Experiments on TIMIT</h2><p>主要讲的是探索究竟在啥层面(时域，时频等)上进行分析会更好(其实我之前也有这方面的困惑)。</p>
<p>涉及到一些数学推导，没来得及慢慢啃</p>
<h3 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h3><p>主要是语音识别领域，作者认为随着识别模型从<code>Gaussian Mixture Model</code>到<code>Deep Neural Networks</code>的转变，那些以前为了GMM而发展出来的特征表示(比如MFCC等)可能并不会在DNN上表现良好。(PS:这个在<code>tasnet</code>那个论文前面也有提到，那个作者提到了在时频上分析会有信号相位和幅度的解耦等问题，所以转换为了时域，并通过conv1D卷积构成的encoder来提取时域wavform上的特征。但是U1s1我感觉这种挺反直觉的，因为讲道理传统的音频处理肯定首先通过傅里叶变换处理之后会好操作很多。关于MFCC的原理等，之后再总结，目前先将其构想成一个从音频中提取特征的黑盒子应该即可)</p>
<p>前面介绍了<code>Speech analysis and time-frequency resolution</code>，也就是DFT、STFT、MFCC等一些的原理 </p>
<h1 id="语音"><a href="#语音" class="headerlink" title="语音"></a>语音</h1><h2 id="Speech-Recognition"><a href="#Speech-Recognition" class="headerlink" title="Speech Recognition"></a>Speech Recognition</h2><p><code>speech recognition</code>即语音识别，可以表示为如图所示的一种变换，即输入的是代表语音的一些特征表示，通常为一系列向量。在下图中即被定义为一个长度为$T$的向量组，每个向量的维度为$d$。而输出是语言文字，众所周知语言分为很多种，例如中文英文等等，但是其均可抽象为一系列token的序列。对于我们想要转换的目标，其token总数可以记为$V$,那么输出就可以表示为一个长度为$N$的token(向量)序列，并且token种类最多有$V$种(感觉可以理解为长度为$V$的one-hot编码？)</p>
<p>先说token，常见的token表示分为$Phoneme$ (音素，感觉可以理解为类似英文英标或者中文拼音的一类东西？),$Grapheme$(字素，比如英文的字母，中文的汉字等等),$Word$,$Morpheme$等等。这取决于我们想要细分的粒度。甚至我们还能将UTF-8编码当成token。</p>
<p><img src="https://s2.loli.net/2024/09/03/9bj8yMOrVsUx5eA.png" alt=""></p>
<p>再说speech输入的vector sequence，众所周知我们能够获取的声音源数据类似波形或者频谱之类的，我们需要将声音信号(也就是Acoustic Feature,声音特征)转为计算机可以理解的vector形式(这一步可以称之为encoder)</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240902212412883.png" alt="image-20240902212412883"></p>
<p>每次设定一个时间窗口(例如图中是25ms的窗口)，然后采集该窗口里的值,为一个向量(称为frame)</p>
<p>比如一种方法是，假如frequency rate为 16KHz，那么在25ms中就能采集到400个sample，对应400个点值组成的向量。</p>
<p>但是这并不是一个推荐的方法。还有其他方法比如39-dim MFCC等(此处可以展开入栈式搜索)</p>
<p><code>Speech Recognition</code>主要分为两种模型，一种是<code>seq-to-seq</code>,这种主要是是利用了机器学习的想法，还有一种是<code>HMM</code>，可能使用的是比较传统的思路</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240903214633344.png" alt="image-20240903214633344"></p>
<h3 id="seq-to-seq"><a href="#seq-to-seq" class="headerlink" title="seq-to-seq"></a>seq-to-seq</h3><p>这里主要介绍了这几个模型，拿LAS举例，其典型的遵循了Encoder-&gt;Recognition-&gt;decoder的步骤</p>
<p><img src="https://s2.loli.net/2024/09/03/J73xpUYQuDFA8Zl.png" alt="image-20240903214909595"></p>
<p>下面记录一下LAS，这里$x_1,\dots,x_n$代表了声学特征，比如MFCC等的output，再讲过encoder之后将其提升到了一个high-level的表示(换句话说这一步实际上是类似于预处理，去掉了原始语音的noise等等，并提取其特征以及内容信息等等)，这里方法主要是使用RNN，CNN以及采用Self-attention等等</p>
<p><img src="https://s2.loli.net/2024/09/03/dCIyVEeo9lhHRYQ.png" alt="image-20240903215207305"></p>
<p>这种是声学特征和high-level表示输出数量一致的情况，但我们知道声学特征可能比较得冗余，这样使得我们中间的attention部分会比较大，如果我们需要对其进行精简使得得到的high-level更纯，就使用down sampling，比如下图左边采用的是pyramid RNN方法。</p>
<p>down sampling的方法还有很多，还有类似Dilated CNN等。</p>
<p><img src="https://s2.loli.net/2024/09/03/gIEMY4Qi2DHsOaz.png" alt="image-20240903220027399"></p>
<p>然后便是attention部分，这应该是比较核心的内容，其目的就是搜寻与匹配。</p>
<p>某个关键词$v_0$与encoder输出进行match，输出一个值(衡量了其相似性)。这种计算attention方式有很多，比如additive attention计算方式如右所示，两个输入向量做一个transfrom，相加再tanh然后再做transform，输入一个标量</p>
<p><img src="https://s2.loli.net/2024/09/03/27XQRlLnrNyzKPm.png" alt="image-20240903220352037"></p>
<p>然后每个$z_0$和这所有的$h$做一个attention，过一个softmax，再作带权和得到$c_0$,这个$c_0$(常常叫做content vector)将会在我们的decoder部分作为一个input</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240903220813133.png" alt="image-20240903220813133"></p>
<p> 这里一般$c_0$经过RNN输出的时候乘以hidden state，然后再过一个transform就能得到一个distribution，给出了对输出每一个token的几率。同时注意到这里decoder的输出大小实际上取决于我们选区的token类型。</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240903221219326.png" alt="image-20240903221219326"></p>
<p>依次类推，中间的hidden_state $z_1$会再经过attention输出一个分布$c_1$，同时它会变成下一个hidden state的输入。</p>
<p><img src="https://s2.loli.net/2024/09/03/5M6DndmzKEwp4ua.png" alt="image-20240903221632434"></p>
<p>同时这里存在一个Bean Search的问题。简而言之就是我们每次贪心地获取每一次decode的输出概率最高的哪一个，但是它不一定是全局最优的。其实我们可以将其抽象成一个算法问题，假设我们有$V$个token，每一次选择的时候会形成一个树状结构(会形成一个完全$V$叉树，同时每个父子结点的连线有一个权值,代表了路径概率。那么我们希望得到一个从根节点到叶子节点的路径权值乘积最小值</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240903221933214.png" alt="image-20240903221933214"></p>
<p>然后我们说其训练过程，比如我们已经知道某段语音说的就是cat这个单词，我们会将第一个输出与$c$表示的one-hot vector做一个交叉熵作为其损失函数。重复这个过程即可。</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240903224241805.png" alt="image-20240903224241805"></p>
<p>但是实际上这里有一个问题，因为我们在进行第二个预测的时候实际上第一个预测结果会输入进我们的hidden state，如果我们预测错了会影响第二次的预测与训练。所以训练的时候采取了一个叫做teacher forcing的技术</p>
<p><img src="C:\Users\YPJ\AppData\Roaming\Typora\typora-user-images\image-20240903225017944.png" alt="image-20240903225017944"></p>
<h2 id="Speech-separation"><a href="#Speech-separation" class="headerlink" title="Speech separation"></a>Speech separation</h2><p>大体上可以分为<code>speech Enhancement</code>以及<code>Speaker Separation</code> .</p>
<p>其Evaluation方法有</p>
<ul>
<li>Signal-to-noise(SNR)(不太好)</li>
<li>Scale invariant signal-to-distortion ratio (SI-SDR) </li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/467017218">手撕 CNN 经典网络之 AlexNet（理论篇） - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7262269863343079479">TCN时间卷积网络：让时间也能“卷”起来TCN时间卷积网络在时序数据建模方面具有许多优点和应用前景。它采用了因果卷积和扩 - 掘金 (juejin.cn)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/LXP-Never/p/11071911.html">语音主观和客观评价总结与实现 - 凌逆战 - 博客园 (cnblogs.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33173246">详解深度学习中的Normalization，BN/LN/WN - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://fancyerii.github.io/books/asr-hmm/">基于HMM的语音识别(一) - 李理的博客 (fancyerii.github.io)</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Photon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://phot0n.com/2024/07/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">http://phot0n.com/2024/07/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/08/29/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"><img class="prev-cover" src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">算法学习</div></div></a></div><div class="next-post pull-right"><a href="/2024/07/29/SICP%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"><img class="next-cover" src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">SICP读书笔记</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2022/01/19/K4TwFgDxsJ62tEo.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Photon</div><div class="author-info__description">光子</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">62</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">41</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/photonwork"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/photonwork" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">1.</span> <span class="toc-text">基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.1.</span> <span class="toc-text">模型评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="toc-number">1.1.1.</span> <span class="toc-text">性能度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E5%85%A8%E7%8E%87%E4%B8%8E%E6%9F%A5%E5%87%86%E7%8E%87"><span class="toc-number">1.1.2.</span> <span class="toc-text">查全率与查准率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ROC%E5%92%8CAUC"><span class="toc-number">1.1.3.</span> <span class="toc-text">ROC和AUC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E4%BB%B7%E9%94%99%E8%AF%AF%E6%95%8F%E6%84%9F%E7%8E%87"><span class="toc-number">1.1.4.</span> <span class="toc-text">代价错误敏感率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="toc-number">1.1.5.</span> <span class="toc-text">偏差与方差</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E8%AE%AD%E7%BB%83"><span class="toc-number">1.2.</span> <span class="toc-text">线性模型及其训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#softmax-%E5%9B%9E%E5%BD%92"><span class="toc-number">1.3.</span> <span class="toc-text">softmax 回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="toc-number">1.4.</span> <span class="toc-text">神经网络与感知机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">1.5.</span> <span class="toc-text">过拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E8%A1%B0%E9%80%80"><span class="toc-number">1.5.1.</span> <span class="toc-text">权重衰退</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9A%82%E9%80%80%E6%B3%95"><span class="toc-number">1.5.2.</span> <span class="toc-text">暂退法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0API%E7%BB%84%E4%BB%B6%E4%BD%BF%E7%94%A8"><span class="toc-number">1.6.</span> <span class="toc-text">一些常用的深度学习API组件使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E5%92%8C%E5%9D%97"><span class="toc-number">1.6.1.</span> <span class="toc-text">自定义层和块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%BB%E5%86%99%E4%B8%8E%E5%AD%98%E5%82%A8"><span class="toc-number">1.6.2.</span> <span class="toc-text">读写与存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8GPU"><span class="toc-number">1.6.3.</span> <span class="toc-text">使用GPU</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.7.</span> <span class="toc-text">卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%92%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97"><span class="toc-number">1.7.1.</span> <span class="toc-text">互相关运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%87%E8%81%9A%E5%B1%82"><span class="toc-number">1.7.2.</span> <span class="toc-text">汇聚层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LeNet"><span class="toc-number">1.7.3.</span> <span class="toc-text">LeNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Modern-CNN"><span class="toc-number">1.8.</span> <span class="toc-text">Modern CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AlexNet"><span class="toc-number">1.8.1.</span> <span class="toc-text">AlexNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VGG"><span class="toc-number">1.9.</span> <span class="toc-text">VGG</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ResNet"><span class="toc-number">1.10.</span> <span class="toc-text">ResNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Trainsfromer"><span class="toc-number">1.11.</span> <span class="toc-text">Trainsfromer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">1.12.</span> <span class="toc-text">一些聚类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means%E7%AE%97%E6%B3%95"><span class="toc-number">1.12.1.</span> <span class="toc-text">k-means算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E5%90%91%E9%87%8F%E5%8C%96-LVQ"><span class="toc-number">1.12.2.</span> <span class="toc-text">学习向量化(LVQ)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RNN"><span class="toc-number">1.13.</span> <span class="toc-text">RNN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A5%BF%E7%93%9C%E4%B9%A6%E8%AF%BE%E5%90%8E%E9%A2%98%E9%80%89%E5%81%9A"><span class="toc-number">2.</span> <span class="toc-text">西瓜书课后题选做</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%BB%AA%E8%AE%BA"><span class="toc-number">2.1.</span> <span class="toc-text">一、绪论</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB"><span class="toc-number">3.</span> <span class="toc-text">论文阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Residual-Learning-for-Image-Recognition"><span class="toc-number">3.1.</span> <span class="toc-text">Deep Residual Learning for Image Recognition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Trainsformer-Attention-Is-All-You-Need"><span class="toc-number">3.2.</span> <span class="toc-text">Trainsformer(Attention Is All You Need)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TASNET"><span class="toc-number">3.3.</span> <span class="toc-text">TASNET</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-1"><span class="toc-number">3.3.1.</span> <span class="toc-text">论文阅读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB"><span class="toc-number">3.3.2.</span> <span class="toc-text">代码阅读</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conv-TasNet"><span class="toc-number">3.4.</span> <span class="toc-text">Conv-TasNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TCN%E7%9A%84%E6%83%B3%E6%B3%95"><span class="toc-number">3.5.</span> <span class="toc-text">TCN的想法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Layer-Normalization"><span class="toc-number">3.6.</span> <span class="toc-text">Layer Normalization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Batch-Normalization"><span class="toc-number">3.6.1.</span> <span class="toc-text">Batch Normalization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#layer-Normalization"><span class="toc-number">3.6.2.</span> <span class="toc-text">layer Normalization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Weight-Normalization"><span class="toc-number">3.6.3.</span> <span class="toc-text">Weight Normalization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spex"><span class="toc-number">3.7.</span> <span class="toc-text">Spex</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Speaker-encoder"><span class="toc-number">3.7.1.</span> <span class="toc-text">Speaker encoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Speech-encoder"><span class="toc-number">3.7.2.</span> <span class="toc-text">Speech encoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Speaker-Extractor"><span class="toc-number">3.7.3.</span> <span class="toc-text">Speaker Extractor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Speech-Decoder"><span class="toc-number">3.7.4.</span> <span class="toc-text">Speech Decoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#train"><span class="toc-number">3.7.5.</span> <span class="toc-text">train</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spex-1"><span class="toc-number">3.8.</span> <span class="toc-text">Spex+</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multi-resolution-speech-analysis-for-automatic-speech-recognition-using-deep-neural-networks-Experiments-on-TIMIT"><span class="toc-number">3.9.</span> <span class="toc-text">Multi-resolution speech analysis for automatic speech recognition using deep neural networks: Experiments on TIMIT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation"><span class="toc-number">3.9.1.</span> <span class="toc-text">motivation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%AD%E9%9F%B3"><span class="toc-number">4.</span> <span class="toc-text">语音</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Speech-Recognition"><span class="toc-number">4.1.</span> <span class="toc-text">Speech Recognition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#seq-to-seq"><span class="toc-number">4.1.1.</span> <span class="toc-text">seq-to-seq</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Speech-separation"><span class="toc-number">4.2.</span> <span class="toc-text">Speech separation</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/08/29/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/" title="算法学习"><img src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="算法学习"/></a><div class="content"><a class="title" href="/2024/08/29/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/" title="算法学习">算法学习</a><time datetime="2024-08-29T11:34:52.000Z" title="Created 2024-08-29 19:34:52">2024-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" title="深度学习记录"><img src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习记录"/></a><div class="content"><a class="title" href="/2024/07/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" title="深度学习记录">深度学习记录</a><time datetime="2024-07-31T06:57:07.000Z" title="Created 2024-07-31 14:57:07">2024-07-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/29/SICP%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" title="SICP读书笔记"><img src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SICP读书笔记"/></a><div class="content"><a class="title" href="/2024/07/29/SICP%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" title="SICP读书笔记">SICP读书笔记</a><time datetime="2024-07-29T03:22:55.000Z" title="Created 2024-07-29 11:22:55">2024-07-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/06/wsl2%E4%B8%8Evscode%E4%B8%8Brust%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="wsl2与vscode下rust开发环境配置"><img src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="wsl2与vscode下rust开发环境配置"/></a><div class="content"><a class="title" href="/2024/07/06/wsl2%E4%B8%8Evscode%E4%B8%8Brust%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="wsl2与vscode下rust开发环境配置">wsl2与vscode下rust开发环境配置</a><time datetime="2024-07-06T06:56:26.000Z" title="Created 2024-07-06 14:56:26">2024-07-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/04/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/" title="java动态代理"><img src="https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="java动态代理"/></a><div class="content"><a class="title" href="/2024/07/04/java%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/" title="java动态代理">java动态代理</a><time datetime="2024-07-04T10:32:27.000Z" title="Created 2024-07-04 18:32:27">2024-07-04</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://i.loli.net/2021/10/14/GSfj5BxXTdRqg2o.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2026 By Photon</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><br>
<img src="https://static.dy208.cn/o_1dfilp8ruo521thr1hvf18ji17soa.png">
<a href="https://beian.miit.gov.cn/"  style="color:#f72b07" target="_blank">皖ICP备2022000759号</a></div><div class="footer_custom_text">欢迎来到光子的博客哟(●'◡'●)</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'J3nDf4qkr8OdRFaP64k2k453-gzGzoHsz',
      appKey: 'NXx6F7OYpwVWFbIQPVnw8HvN',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"live2d-widget-model-haruto"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>